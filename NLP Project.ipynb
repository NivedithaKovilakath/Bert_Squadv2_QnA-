{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnURV5y73cFh",
        "outputId": "bd2ad285-af31-42e3-cfb4-1fc11bd4a7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQuPfHc45sjB",
        "outputId": "e5512f20-c5ba-4c9c-d33d-d883d6cb6ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRJmX8PY1vxv"
      },
      "outputs": [],
      "source": [
        "#load all libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from transformers import BertModel, BertTokenizerFast, AdamW, AutoTokenizer, AutoModelForQuestionAnswering, BertTokenizer, BertForQuestionAnswering\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVfxtl7pQi3Y"
      },
      "source": [
        "###Extrinsic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRJBhgMcQh9M"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Specify the path to the downloaded NewsQA JSON file\n",
        "newsqa_file_path = \"combined-newsqa-data-v1.json\"\n",
        "\n",
        "# Load the JSON file\n",
        "with open(newsqa_file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    newsqa_data = json.load(file)\n",
        "\n",
        "# Now `newsqa_data` contains the entire NewsQA dataset\n",
        "# You can access different parts of the dataset based on its structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyxOvC1CawsQ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/amazon-science/qa-dataset-converter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8IvE5JOawpJ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/mandarjoshi90/triviaqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64PC_BYTcBJK"
      },
      "outputs": [],
      "source": [
        "%cd qa-dataset-converter/newsqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjzIkeaygKYg"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cM6UYizbtLS"
      },
      "outputs": [],
      "source": [
        "!python /content/qa-dataset-converter/newsqa/newsqa_to_squad.py --newsqa_file newsqa-data-v1.csv --output_file newsqa_dev.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYq2YgHT4_QN"
      },
      "source": [
        "###Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PM2jZi3T5hIx"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYuzGjfp239U"
      },
      "outputs": [],
      "source": [
        "squad_dataset = load_dataset(\"squad_v2\")\n",
        "# Access the training split\n",
        "train_data = squad_dataset[\"train\"]\n",
        "# Access the validation split\n",
        "validation_data = squad_dataset[\"validation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5K3myps50kW"
      },
      "outputs": [],
      "source": [
        "train_data[140]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqThi15q5_p5"
      },
      "outputs": [],
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLoaAcPT6C0A"
      },
      "outputs": [],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRFuZbNS-GNA"
      },
      "outputs": [],
      "source": [
        "def get_data(data):\n",
        "  title_list = []\n",
        "  context_list = []\n",
        "  question_list = []\n",
        "  answer_list = []\n",
        "  num_questions = 0\n",
        "  num_questions_pos = 0\n",
        "  num_questions_impos = 0\n",
        "\n",
        "  for e in data:\n",
        "    num_questions += 1\n",
        "    if(e['answers']['text']==[]):\n",
        "      #impossible\n",
        "      num_questions_impos += 1\n",
        "    else:\n",
        "      title_list.append(e['title'])\n",
        "      context_list.append(e['context'])\n",
        "      question_list.append(e['question'])\n",
        "      e['answers']['text'] = e['answers']['text'][0]\n",
        "      e['answers']['answer_start'] = e['answers']['answer_start'][0]\n",
        "      answer_list.append(e['answers'])\n",
        "      num_questions_pos += 1\n",
        "\n",
        "  return title_list, context_list, question_list, answer_list, num_questions, num_questions_pos, num_questions_impos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrLUWRomDXyP"
      },
      "outputs": [],
      "source": [
        "title_list_train, context_list_train, question_list_train, answer_list_train, num_questions_train, num_questions_pos_train, num_questions_impos_train = get_data(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ii2sXyV_6TE"
      },
      "outputs": [],
      "source": [
        "title_list_test, context_list_test, question_list_test, answer_list_test, num_questions_test, num_questions_pos_test, num_questions_impos_test= get_data(validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgVHjE3A6HfY"
      },
      "outputs": [],
      "source": [
        "print(f\"Total number of questions: {num_questions_train+num_questions_test}\")\n",
        "print(num_questions_test)\n",
        "print(f\"Total number of Answerable questions: {num_questions_pos_train+num_questions_pos_test}\")\n",
        "print(f\"Total number of impossible questions: {num_questions_impos_train+num_questions_impos_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYTpS-FiD1ox"
      },
      "outputs": [],
      "source": [
        "def add_answer_ends(answers):\n",
        "  for e in answers:\n",
        "    e['text'] = e['text'].lower()\n",
        "    e['answer_end']=[]\n",
        "    e['answer_end'] .append(e['answer_start'] + len(e['text']))\n",
        "    e['answer_end'] = e['answer_end'][0]\n",
        "\n",
        "  return answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZtZ9aFLG8tu"
      },
      "outputs": [],
      "source": [
        "answer_list_train = add_answer_ends(answer_list_train)\n",
        "answer_list_test = add_answer_ends(answer_list_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl1Dv5Vy6pAY"
      },
      "outputs": [],
      "source": [
        "test_rec = 30\n",
        "print(f\"Context: {context_list_test[test_rec]}\")\n",
        "print(f\"Question: {question_list_test[test_rec]}\")\n",
        "print(f\"Answer: {answer_list_test[test_rec]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_irREbsI8Q8"
      },
      "outputs": [],
      "source": [
        "#add for validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhUEPfy9I0qT"
      },
      "source": [
        "###Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W67lUkXsIrEh"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store token lengths\n",
        "token_lengths = []\n",
        "\n",
        "# Loop through each context passage in the text_data list\n",
        "for passage in context_list_train:\n",
        "    # Remove leading and trailing white spaces from the passage\n",
        "    passage = passage.strip()\n",
        "\n",
        "    # Split the cleaned passage into tokens using spaces and count the number of tokens\n",
        "    token_count = len(passage.split())\n",
        "\n",
        "    # Append the token count to the token_lengths list\n",
        "    token_lengths.append(token_count)\n",
        "\n",
        "# Find and print the maximum token length observed in the context passages\n",
        "max_token_length = max(token_lengths)\n",
        "print(f\"Maximum token length in context passages: {max_token_length}\")\n",
        "\n",
        "# Create a histogram to visualize the distribution of token lengths\n",
        "plt.hist(token_lengths, bins=20)\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Token Length')\n",
        "plt.title('Distribution of Context Passage Token Lengths')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS2KJkeaDaD6"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store the token lengths of context passages\n",
        "token_lengths_2 = []\n",
        "\n",
        "# Loop through each context passage in the train_contexts list\n",
        "for question in question_list_train:\n",
        "    # Remove leading and trailing white spaces from the passage\n",
        "    cleaned_question = question.strip()\n",
        "\n",
        "    # Split the cleaned context passage into tokens based on spaces and count the number of tokens\n",
        "    token_count = len(cleaned_question.split(' '))\n",
        "\n",
        "    # Append the token count to the token_lengths list\n",
        "    token_lengths_2.append(token_count)\n",
        "\n",
        "# Find and print the maximum token length observed in the context passages\n",
        "max_token_length = max(token_lengths_2)\n",
        "print(f\"Maximum token length in questions: {max_token_length}\")\n",
        "\n",
        "# Create a histogram to visualize the distribution of token lengths\n",
        "plt.hist(token_lengths_2, bins=20)  # You can adjust the number of bins for your visualization\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Token Length')\n",
        "plt.title('Distribution of Question Token Lengths')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbERB1i_EoGJ"
      },
      "outputs": [],
      "source": [
        "Max_Length = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsxCvpRvFC_Z"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = \"bert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIc4PTjFEqa0"
      },
      "outputs": [],
      "source": [
        "tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
        "\n",
        "train_encodings_fast = tokenizerFast(question_list_train, context_list_train,  max_length = Max_Length, truncation=True, padding=True)\n",
        "test_encodings_fast = tokenizerFast(question_list_test, context_list_test,  max_length = Max_Length, truncation=True, padding=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnEjhJ8FGHcZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(train_encodings_fast.keys())\n",
        "print(test_encodings_fast.keys())\n",
        "print(len(train_encodings_fast['input_ids']))\n",
        "print(train_encodings_fast['input_ids'][10][0:25])\n",
        "print(train_encodings_fast['token_type_ids'][10][0:25])\n",
        "print(train_encodings_fast['attention_mask'][10][0:25])\n",
        "\n",
        "print(len(train_encodings_fast['input_ids'][0]))\n",
        "#attention mask is 0 for padding tokens and 1 for non-padding tokens\n",
        "#input ids is the token integer for each word in the input sequence\n",
        "#token type ids is 0 for questions and 1 for contexts - used in a multi-input model\n",
        "\n",
        "#DOUBT ?? how do we combine the 2 inputs into a single 250 length object?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-nXVtaBGOXP"
      },
      "outputs": [],
      "source": [
        "# # Select the first sequence (index 0) from input_ids\n",
        "# input_ids_sequence = train_encodings_fast['input_ids'][10]\n",
        "# decoded_sequence = tokenizerFast.decode(input_ids_sequence, skip_special_tokens=True)\n",
        "# print(len(decoded_sequence.split(' ')))\n",
        "# print(type(decoded_sequence))\n",
        "# print(decoded_sequence)\n",
        "# print(len(context_list_train[0].split(' ')))\n",
        "# print(context_list_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnnQATrr_rlR"
      },
      "outputs": [],
      "source": [
        "answer_list_test[101]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRF8voaV7vYp"
      },
      "outputs": [],
      "source": [
        "answer_encoding_fast = tokenizerFast(answer_list_train[0]['text'],  max_length = Max_Length, truncation=True, padding=True)\n",
        "answer_encoding_fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVI3cuZb0j1p"
      },
      "outputs": [],
      "source": [
        "def ret_Answer_start_and_end_train(idx):\n",
        "    ret_start = 0\n",
        "    ret_end = 0\n",
        "    answer_encoding_fast = tokenizerFast(answer_list_train[idx]['text'],  max_length = Max_Length, truncation=True, padding=True)\n",
        "    for a in range( len(train_encodings_fast['input_ids'][idx]) -  len(answer_encoding_fast['input_ids']) ): #len(train_encodings_fast['input_ids'][0])):\n",
        "        match = True\n",
        "        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n",
        "\n",
        "            if (answer_encoding_fast['input_ids'][i] != train_encodings_fast['input_ids'][idx][a + i]):\n",
        "                match = False\n",
        "                break\n",
        "        if match:\n",
        "            ret_start = a+1\n",
        "            ret_end = a+i+1\n",
        "            break\n",
        "    return(ret_start, ret_end)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-Z_5RcrCm6E"
      },
      "outputs": [],
      "source": [
        "def ret_Answer_start_and_end_test(idx):\n",
        "    ret_start = 0\n",
        "    ret_end = 0\n",
        "    answer_encoding_fast = tokenizerFast(answer_list_test[idx]['text'],  max_length = Max_Length, truncation=True, padding=True)\n",
        "    for a in range( len(test_encodings_fast['input_ids'][idx])  -  len(answer_encoding_fast['input_ids'])   ): #len(train_encodings_fast['input_ids'][0])):\n",
        "        match = True\n",
        "        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n",
        "            if (answer_encoding_fast['input_ids'][i] != test_encodings_fast['input_ids'][idx][a + i]):\n",
        "                match = False\n",
        "                break\n",
        "        if match:\n",
        "            ret_start = a+1\n",
        "            ret_end = a+i+1\n",
        "            break\n",
        "    return(ret_start, ret_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSY8jcjXQhHt"
      },
      "outputs": [],
      "source": [
        "def calc_answer_start_end_train(index):\n",
        "  start=0\n",
        "  end=0\n",
        "  answer_encoding_fast = tokenizerFast(answer_list_train[index]['text'],  max_length = Max_Length, truncation=True, padding=True)\n",
        "  l = len(answer_list_train[index]['text'][0].split(' '))\n",
        "\n",
        "\n",
        "\n",
        "  for x in range(len(train_encodings_fast['input_ids'][index]) - l):\n",
        "    match = True\n",
        "    for i in range(l):\n",
        "      if(answer_encoding_fast['input_ids'][0][i+1]!=train_encodings_fast['input_ids'][index][x+i]):\n",
        "        match = False\n",
        "        break\n",
        "    if(match):\n",
        "      start = x\n",
        "      end = x+l\n",
        "      break\n",
        "  return start,end\n",
        "    # if answer_encoding_fast['input_ids'][0]  ==  train_encodings_fast['input_ids'][index][x:x+len(answer_encoding_fast['input_ids'][0])]:\n",
        "    #   start = x+1\n",
        "    #   end = x+len(answer_encoding_fast['input_ids'][0])+1\n",
        "    #   break\n",
        "  # return start,end\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgJpPMAQcy8J"
      },
      "outputs": [],
      "source": [
        "# print(len(train_encodings_fast['input_ids'][10]))\n",
        "# answer_encoding_fast = tokenizerFast(answer_list_train[10]['text'],  max_length = 250, truncation=True, padding=True)\n",
        "# # input_ids_sequence = train_encodings_fast['input_ids'][0]\n",
        "# # decoded_sequence = tokenizerFast.decode(input_ids_sequence)\n",
        "# # print(len(decoded_sequence.split(' ')))\n",
        "# print(len(answer_list_train[10]['text'][0].split(' ')))\n",
        "# print(len(answer_encoding_fast['input_ids'][0]))\n",
        "# decoded_sequence = tokenizerFast.decode(answer_encoding_fast['input_ids'][0])\n",
        "# print(decoded_sequence)\n",
        "# print(answer_encoding_fast['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V95wHUdcV5h_"
      },
      "outputs": [],
      "source": [
        "# test_rec=0\n",
        "\n",
        "# z,x = calc_answer_start_end_train(test_rec)\n",
        "# print(z, x)\n",
        "\n",
        "# predict_answer_tokens = train_encodings_fast.input_ids[test_rec][z : x]\n",
        "# print(tokenizerFast.decode(predict_answer_tokens))\n",
        "# print(answer_list_train[test_rec]['text'])\n",
        "# print(tokenizerFast.decode(train_encodings_fast['input_ids'][test_rec]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXHQkFFOL2iy"
      },
      "outputs": [],
      "source": [
        "start_positions = []\n",
        "end_positions = []\n",
        "ctr = 0\n",
        "for h in range(len(train_encodings_fast['input_ids'])):\n",
        "  #print(h)\n",
        "  s, e = ret_Answer_start_and_end_train(h)\n",
        "\n",
        "  start_positions.append(s)\n",
        "  end_positions.append(e)\n",
        "  if s==0:\n",
        "    ctr = ctr + 1\n",
        "\n",
        "train_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "print(ctr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FZdIqm0X0zw"
      },
      "outputs": [],
      "source": [
        "train_encodings_fast.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPPBJravidtQ"
      },
      "outputs": [],
      "source": [
        "def calc_answer_start_end_test(index):\n",
        "  start=0\n",
        "  end=0\n",
        "  answer_encoding_fast = tokenizerFast(answer_list_test[index]['text'],  max_length = Max_Length, truncation=True, padding=True)\n",
        "  l = len(answer_list_test[index]['text'][0].split(' '))\n",
        "\n",
        "\n",
        "\n",
        "  for x in range(len(test_encodings_fast['input_ids'][index]) - l):\n",
        "    match = True\n",
        "    for i in range(l):\n",
        "      if(answer_encoding_fast['input_ids'][0][i+1]!=test_encodings_fast['input_ids'][index][x+i]):\n",
        "        match = False\n",
        "        break\n",
        "    if(match):\n",
        "      start = x\n",
        "      end = x+l\n",
        "      break\n",
        "  return start,end\n",
        "    # if answer_encoding_fast['input_ids'][0]  ==  train_encodings_fast['input_ids'][index][x:x+len(answer_encoding_fast['input_ids'][0])]:\n",
        "    #   start = x+1\n",
        "    #   end = x+len(answer_encoding_fast['input_ids'][0])+1\n",
        "    #   break\n",
        "  # return start,end\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzfU2-utkjcj"
      },
      "outputs": [],
      "source": [
        "start_positions = []\n",
        "end_positions = []\n",
        "ctr = 0\n",
        "for h in range(len(test_encodings_fast['input_ids'])):\n",
        "    #print(h)\n",
        "    s, e = ret_Answer_start_and_end_test(h)\n",
        "\n",
        "    start_positions.append(s)\n",
        "    end_positions.append(e)\n",
        "    if s==0:\n",
        "        ctr = ctr + 1\n",
        "\n",
        "\n",
        "test_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "print(ctr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCJHmWG1cuOT"
      },
      "source": [
        "OPTIONAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDDDlfIwkn84"
      },
      "outputs": [],
      "source": [
        "tokenizer2 = BertTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
        "model2 = BertForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW7PYyd-cxGO"
      },
      "outputs": [],
      "source": [
        "question= question_list_train[2]\n",
        "text = context_list_train[2]\n",
        "\n",
        "print(question)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN-ZlQPyc1Te"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer2(question, text, return_tensors=\"pt\", padding=True, truncation=True, max_length = Max_Length)\n",
        "with torch.no_grad():\n",
        "  outputs = model2(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjOS6Tw4Ss2g"
      },
      "outputs": [],
      "source": [
        "print(len(train_encodings_fast['input_ids']))\n",
        "print(inputs[\"attention_mask\"].shape)\n",
        "print(inputs[\"token_type_ids\"].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F_oepDcc5pX"
      },
      "outputs": [],
      "source": [
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()\n",
        "print(answer_start_index)\n",
        "print(answer_end_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0AIUPPOc7nB"
      },
      "outputs": [],
      "source": [
        "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer2.decode(predict_answer_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHPST4cIgiBC"
      },
      "source": [
        "Creating Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA----DCghks"
      },
      "outputs": [],
      "source": [
        "class InputDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "    def __getitem__(self, i):\n",
        "        return {\n",
        "            'inputIDs': torch.tensor(self.encodings['input_ids'][i]),\n",
        "            'tokenIDs': torch.tensor(self.encodings['token_type_ids'][i]),\n",
        "            'attMask': torch.tensor(self.encodings['attention_mask'][i]),\n",
        "            'startPos': torch.tensor(self.encodings['start_positions'][i]),\n",
        "            'endPos': torch.tensor(self.encodings['end_positions'][i])\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkWh0cbSk3gU"
      },
      "outputs": [],
      "source": [
        "train_dataset = InputDataset(train_encodings_fast)\n",
        "test_dataset = InputDataset(test_encodings_fast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSckqfjWk7BB"
      },
      "outputs": [],
      "source": [
        "# print(len(train_dataset))\n",
        "# print(train_dataset.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3xk3AD4k9GN"
      },
      "outputs": [],
      "source": [
        "train_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=32)\n",
        "# TODO: change the batch_size later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "narfmCAgRp66"
      },
      "source": [
        "Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93AtxO2elEWd"
      },
      "outputs": [],
      "source": [
        "#model = BertForQuestionAnswering.from_pretrained(MODEL_PATH)\n",
        "bert_model = BertModel.from_pretrained(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSZaXg3MR8rR"
      },
      "outputs": [],
      "source": [
        "print(bert_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIo52Whzzh3A"
      },
      "outputs": [],
      "source": [
        "#no_layers = 6\n",
        "#for param in bert_model.encoder.layer[:no_layers].parameters():\n",
        "#    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2a4iujsSDun"
      },
      "outputs": [],
      "source": [
        "#defining the model\n",
        "\n",
        "class QAModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QAModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.drop_out = nn.Dropout(0.1)\n",
        "        self.l1 = nn.Linear(768*2, 384 )\n",
        "        self.l2 = nn.Linear(384 , 2)\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            self.drop_out,\n",
        "            self.l1,\n",
        "            nn.LeakyReLU(),\n",
        "            self.l2\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
        "        hidden_states = model_output[2]\n",
        "\n",
        "        #original implementation\n",
        "        #out= hidden_states[-1]\n",
        "\n",
        "        #our innovation\n",
        "        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1) # taking Start logits from last BERT layer, End Logits from third to last layer\n",
        "\n",
        "        logits = self.linear_relu_stack(out)\n",
        "\n",
        "        ans_start_index, ans_end_index = logits.split(1, dim=-1)\n",
        "\n",
        "        ans_start_index = ans_start_index.squeeze(-1)\n",
        "        ans_end_index = ans_end_index.squeeze(-1)\n",
        "\n",
        "        return ans_start_index, ans_end_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKmoMf_9pvY_"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class QAModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QAModel, self).__init__()\n",
        "        self.bert = bert_model  # Assuming `bert_model` is defined elsewhere\n",
        "        self.drop_out = nn.Dropout(0.1)\n",
        "        self.lstm = nn.LSTM(768, 384, bidirectional=True, batch_first=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_stack = nn.Sequential(\n",
        "            nn.Linear(768, 384),\n",
        "            self.relu,\n",
        "            nn.Linear(384 * 2, 2)  # Adjusted the input size based on LSTM bidirectional output\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
        "        hidden_states = model_output[2]\n",
        "\n",
        "        # Concatenate the hidden states from the last two layers\n",
        "        out = torch.cat((hidden_states[-1], hidden_states[-2]), dim=-1)\n",
        "\n",
        "        # Apply dropout\n",
        "        out = self.drop_out(out)\n",
        "\n",
        "        # Apply LSTM\n",
        "        out, _ = self.lstm(out)\n",
        "\n",
        "        # Flatten the output before passing through linear layers\n",
        "        out = out.contiguous().view(out.size(0), -1)\n",
        "\n",
        "        # Apply linear layers\n",
        "        logits = self.linear_stack(out)\n",
        "\n",
        "        ans_start_index, ans_end_index = logits.split(1, dim=-1)\n",
        "\n",
        "        ans_start_index = ans_start_index.squeeze(-1)\n",
        "        ans_end_index = ans_end_index.squeeze(-1)\n",
        "\n",
        "        return ans_start_index, ans_end_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiaNqvXBNbee"
      },
      "outputs": [],
      "source": [
        "model = QAModel()\n",
        "\n",
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsfPLqobZWtz",
        "outputId": "5141eeed-08fe-4b20-83ea-e1d8123fdb9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['inputIDs', 'tokenIDs', 'attMask', 'startPos', 'endPos'])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiET6BBTl6rL",
        "outputId": "1bcbbccb-48ad-46a4-a74f-b8f6b4898bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 250])\n"
          ]
        }
      ],
      "source": [
        "print(data['inputIDs'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0MbwyFBZgHF"
      },
      "outputs": [],
      "source": [
        "#run one row\n",
        "'''\n",
        "model.to(device)\n",
        "model.train()\n",
        "input_ids = data['inputIDs'][0].unsqueeze(0).to(device)\n",
        "attention_mask = data['attMask'][0].unsqueeze(0).to(device)\n",
        "start_positions = data['startPos'][0].unsqueeze(0).to(device)\n",
        "end_positions = data['endPos'][0].unsqueeze(0).to(device)\n",
        "token_type_ids = data['tokenIDs'][0].unsqueeze(0).to(device)\n",
        "\n",
        "out_start, out_end = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO7XdJfrZvxD"
      },
      "outputs": [],
      "source": [
        "#print(f\"start logits shape: {out_start.shape}\")\n",
        "#print(f\"end logits shape: {out_end.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPoT1XIkgvJK"
      },
      "outputs": [],
      "source": [
        "#answer_start_index = out_start.argmax()\n",
        "#answer_end_index = out_end.argmax()\n",
        "#print(answer_start_index)\n",
        "#print(answer_end_index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "E5Ph8prshJCi",
        "outputId": "f0054fc8-781f-4aeb-bc97-a26fbb0ad532"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"predict_answer_tokens = data['inputIDs'][0, answer_start_index]\\npredict_answer_end_tokens = data['inputIDs'][0, answer_end_index]\\n# tokenizer2.decode(predict_answer_tokens)\\ntokenizerFast.decode(predict_answer_end_tokens)\\n\""
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''predict_answer_tokens = data['inputIDs'][0, answer_start_index]\n",
        "predict_answer_end_tokens = data['inputIDs'][0, answer_end_index]\n",
        "# tokenizer2.decode(predict_answer_tokens)\n",
        "tokenizerFast.decode(predict_answer_end_tokens)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNARZfOvlRid"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_SRTF5yOtEa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-NNVVznWmC9"
      },
      "outputs": [],
      "source": [
        "%cd '/content/drive/MyDrive/BITS_NLP'\n",
        "#%cd '/content/drive/MyDrive/BITS_NLP'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ECXEPC8B-8d"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('checkpoint.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crz1QhZ1YZJN"
      },
      "outputs": [],
      "source": [
        "#import trained model\n",
        "#model = QAModel()\n",
        "#model.load_state_dict(torch.load('checkpoint.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_HjdYgOZL2_",
        "outputId": "cc3fb0f7-db5c-433c-a692-ad42ad1a58eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oKjF6wWliW8a",
        "outputId": "f64132dd-72a9-410f-8046-682cc5f441e2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' = 2e-5\\nweight_decay = 2e-2\\ngamma = 0.9\\noptimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\\nloss_fn1 = nn.CrossEntropyLoss()\\nscheduler = ExponentialLR(optimizer1, gamma=gamma)\\ntotal_accuracy = []\\ntotal_loss = []\\n'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' = 2e-5\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "optimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn1 = nn.CrossEntropyLoss()\n",
        "scheduler = ExponentialLR(optimizer1, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMqGFHQFmxOa"
      },
      "outputs": [],
      "source": [
        "def train(model, data, epochNumber, optimizer, loss_fn, name):\n",
        "  model = model.train()\n",
        "  loss_list = []\n",
        "  accuracy_list = []\n",
        "  count = 0\n",
        "  batch_count = 0\n",
        "  #batch_save=0\n",
        "  for batch in tqdm(data, desc = 'Current epoch number '):\n",
        "    optimizer.zero_grad()\n",
        "    input_ids = batch['inputIDs'].to(device)\n",
        "    attention_mask = batch['attMask'].to(device)\n",
        "    token_type_ids = batch['tokenIDs'].to(device)\n",
        "    start_positions = batch['startPos'].to(device)\n",
        "    end_positions = batch['endPos'].to(device)\n",
        "    out_start, out_end = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "    #loss = loss_fn(out_start, out_end, start_positions, end_positions)  # <---BASELINE.  Cross Entropy Loss is returned by Default\n",
        "\n",
        "    loss = loss_fn(out_start, start_positions) + loss_fn(out_end, end_positions)\n",
        "    loss_list.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    start_prediction = torch.argmax(out_start, dim=1)\n",
        "    end_prediction = torch.argmax(out_end, dim=1)\n",
        "\n",
        "    accuracy_list.append(((start_prediction == start_positions).sum()/len(start_prediction)).item())\n",
        "    accuracy_list.append(((end_prediction == end_positions).sum()/len(end_prediction)).item())\n",
        "    batch_count = batch_count + 1\n",
        "    #batch_save=batch_save+1\n",
        "    if batch_count==250:\n",
        "        total_accuracy.append(sum(accuracy_list)/len(accuracy_list))\n",
        "        loss_average = sum(loss_list)/len(loss_list)\n",
        "        total_loss.append(loss_average)\n",
        "        if epochNumber==1:\n",
        "          print(\"current accuracy : \" + str(total_accuracy[-1]))\n",
        "          print(\"current loss : \" + str(total_loss[-1]))\n",
        "        batch_count = 0\n",
        "        if total_accuracy[-1]==max(total_accuracy):\n",
        "          torch.save(model.state_dict(), name)\n",
        "          print(\"Saving the model for epoch number \"+ str(epochNumber))\n",
        "\n",
        "  scheduler.step()\n",
        "  ret_acc = sum(accuracy_list)/len(accuracy_list)\n",
        "  ret_loss = sum(loss_list)/len(loss_list)\n",
        "  return(ret_acc, ret_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA9CYIVDaY0I"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, dataloader):\n",
        "    model = model.eval()\n",
        "    acc = []\n",
        "    ctr = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc = 'Running Evaluation'):\n",
        "            input_ids = batch['inputIDs'].to(device)\n",
        "            attention_mask = batch['attMask'].to(device)\n",
        "            token_type_ids = batch['tokenIDs'].to(device)\n",
        "            start_true = batch['startPos'].to(device)\n",
        "            end_true = batch['endPos'].to(device)\n",
        "\n",
        "            out_start, out_end = model(input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "\n",
        "            start_pred = torch.argmax(out_start, dim=1)\n",
        "            end_pred = torch.argmax(out_end, dim=1)\n",
        "\n",
        "            acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
        "            acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
        "\n",
        "        ret_acc = sum(acc)/len(acc)\n",
        "        #ret_loss = 0\n",
        "        #ret_loss = sum(losses)/len(losses)\n",
        "\n",
        "\n",
        "    return acc, ret_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxIqSeXvb514"
      },
      "source": [
        "###Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip8irHOSr84H",
        "outputId": "234d9043-9e03-46b9-c658-414619d66791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch number is 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 250/2714 [06:01<59:57,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.3128125\n",
            "current loss : 5.850066661834717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 500/2714 [12:07<53:49,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.426\n",
            "current loss : 4.659376241922379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 750/2714 [18:13<48:11,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.4783541666666667\n",
            "current loss : 4.122625838120778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 999/2714 [24:18<42:06,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.51046875\n",
            "current loss : 3.8032863845825196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  37%|███▋      | 1000/2714 [24:21<56:41,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  46%|████▌     | 1250/2714 [30:28<35:45,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.532875\n",
            "current loss : 3.585979307842255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  55%|█████▌    | 1500/2714 [36:35<29:38,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.54984375\n",
            "current loss : 3.427627196709315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  64%|██████▍   | 1750/2714 [42:41<23:27,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5623571428571429\n",
            "current loss : 3.304431213378906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 1999/2714 [48:46<17:31,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5737578125\n",
            "current loss : 3.198438799440861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  74%|███████▎  | 2000/2714 [48:53<36:22,  3.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2250/2714 [55:00<11:20,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5815069444444444\n",
            "current loss : 3.1166555647320218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2500/2714 [1:01:07<05:14,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.58963125\n",
            "current loss : 3.0365468365192414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:06:20<00:00,  1.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.595797254976404      Train Loss: 2.9818682467665143\n",
            "epoch number is 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 1000/2714 [24:28<1:03:13,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 2000/2714 [48:58<26:44,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:06:21<00:00,  1.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.7231749723677083      Train Loss: 1.8281613364980427\n",
            "epoch number is 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 1000/2714 [24:23<55:36,  1.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 2000/2714 [48:45<23:07,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:06:06<00:00,  1.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.7843162767155344      Train Loss: 1.3491209464294558\n",
            "epoch number is 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  22%|██▏       | 604/2714 [14:44<51:25,  1.46s/it]"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer1, loss_fn1)\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n",
        "\n",
        "    #if epoch==2:\n",
        "      #val_acc, val_loss = eval_model(model, test_data_loader)\n",
        "      #print(f\"Testing Accuracy: {val_acc}   Testing Loss: {val_loss}\")\n",
        "    # val_acc = eval_model(model, valid_data_loader)\n",
        "    # print(f\"Validation Accuracy: {val_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMk3zbEIXAud"
      },
      "outputs": [],
      "source": [
        "#model = QAModel()\n",
        "#model.load_state_dict(torch.load('checkpoint.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHdvLum9W9kt",
        "outputId": "f43cd64b-3162-4b80-a2c7-49fca67c5022"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:32<00:00,  2.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.6772513440860215 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing after training for three iterations\n",
        "\n",
        "acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "print(f\"Testing Accuracy: {test_acc} \" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE3LG6MUpszv"
      },
      "outputs": [],
      "source": [
        "# saving in drive\n",
        "torch.save(model.state_dict(), '/kaggle/working/best_model_state.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR5d3uExsEpY"
      },
      "outputs": [],
      "source": [
        "# plot Accuracy\n",
        "plt.plot(total_acc, color='blue')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Runs->')\n",
        "plt.title(\"Total Train Accuracy over time\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV_tu2p6o-wa"
      },
      "outputs": [],
      "source": [
        "# plot Loss\n",
        "plt.plot(total_loss, color='red')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Runs->')\n",
        "plt.title(\"Total Train Loss over time\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcJtJVKpGzWY"
      },
      "outputs": [],
      "source": [
        "# plot Accuracy\n",
        "plt.plot(total_acc, color='blue')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Runs->')\n",
        "plt.title(\"Total Train Accuracy over time\");\n",
        "\n",
        "\n",
        "# plot Loss\n",
        "plt.plot(total_loss, color='red')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Runs->')\n",
        "plt.title(\"Total Train Loss over time\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AERYt27DCMfB"
      },
      "source": [
        "###ZERO shot learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRQC84D1CP2G"
      },
      "outputs": [],
      "source": [
        "model = QAModel()\n",
        "\n",
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEgc4wNFCPyp",
        "outputId": "0f2a17bb-7c98-4d23-eeaf-153be39dd2da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:25<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.006132392473118279 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "print(f\"Testing Accuracy: {test_acc} \" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqc1zLj_h5gn"
      },
      "source": [
        "###Adding a LSTM layer-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_JQGD0rh9-_",
        "outputId": "a349365b-d4a0-4c34-db1b-1507bc0afa65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on CUDA (GPU).\n"
          ]
        }
      ],
      "source": [
        "model = QAModel()\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "\n",
        "if next(model.parameters()).is_cuda:\n",
        "    print(\"Model is on CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"Model is on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFmuvGoOh96t"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-5\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "optimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn1 = nn.CrossEntropyLoss()\n",
        "scheduler = ExponentialLR(optimizer1, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "_3uq5Dyvh92f",
        "outputId": "20830027-d56f-4237-a420-c2c4e76df536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch number is 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   0%|          | 0/2714 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:879: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "Current epoch number :   0%|          | 0/2714 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-d2e2f73759d5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch number is \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_lstm.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0macc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-49b9f216cfba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, epochNumber, optimizer, loss_fn, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'startPos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mend_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'endPos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mout_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#loss = loss_fn(out_start, out_end, start_positions, end_positions)  # <---BASELINE.  Cross Entropy Loss is returned by Default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-24bb12d10cb3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Apply LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Flatten the output before passing through linear layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    880\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[2359296, 1]' is invalid for input of size 1179648"
          ]
        }
      ],
      "source": [
        "#training\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer1, loss_fn1, 'model_lstm.pth')\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n",
        "    acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "    print(f\"Testing accuracy after epoch {epoch} is {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNXWwutgd2rc"
      },
      "source": [
        "###Different Model Architectures - linear layer is 768*2 - 384 final layer is 384 * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaFUJYGvd7F0",
        "outputId": "fe5dfae3-934e-47e1-ddfe-65b697b26e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on CUDA (GPU).\n"
          ]
        }
      ],
      "source": [
        "model = QAModel()\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "\n",
        "if next(model.parameters()).is_cuda:\n",
        "    print(\"Model is on CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"Model is on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnODo01Id7Av"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-5\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "optimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn1 = nn.CrossEntropyLoss()\n",
        "scheduler = ExponentialLR(optimizer1, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er9Ie6HPd645",
        "outputId": "f7ca31f5-1186-4181-bdeb-d56d1c8e4911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch number is 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 249/2714 [05:38<56:36,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.2964375\n",
            "current loss : 6.063306154251099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :   9%|▉         | 250/2714 [05:43<1:43:08,  2.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 499/2714 [11:28<51:16,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.4158125\n",
            "current loss : 4.79327962231636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  18%|█▊        | 500/2714 [11:31<1:07:41,  1.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 749/2714 [17:15<45:23,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.47127083333333336\n",
            "current loss : 4.21756974140803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  28%|██▊       | 750/2714 [17:18<1:00:48,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 999/2714 [23:03<39:44,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5055\n",
            "current loss : 3.8783347203731537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  37%|███▋      | 1000/2714 [23:08<1:09:26,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  46%|████▌     | 1249/2714 [28:52<33:48,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5268625\n",
            "current loss : 3.6604588099479676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  46%|████▌     | 1250/2714 [28:55<45:02,  1.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  55%|█████▌    | 1499/2714 [34:39<28:06,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.54315625\n",
            "current loss : 3.4973766616980235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  55%|█████▌    | 1500/2714 [34:43<38:41,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  64%|██████▍   | 1749/2714 [40:27<22:14,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5573392857142857\n",
            "current loss : 3.355613072531564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  64%|██████▍   | 1750/2714 [40:30<29:36,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 1999/2714 [46:14<16:30,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.568953125\n",
            "current loss : 3.24571166908741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  74%|███████▎  | 2000/2714 [46:18<22:40,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2249/2714 [52:02<10:44,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5785902777777778\n",
            "current loss : 3.1543400825394525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  83%|████████▎ | 2250/2714 [52:08<20:52,  2.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2499/2714 [57:52<04:56,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5868625\n",
            "current loss : 3.074198183679581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  92%|█████████▏| 2500/2714 [57:55<06:35,  1.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:02:50<00:00,  1.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.5929681742858957      Train Loss: 3.014860570782146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:28<00:00,  2.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing accuracy after epoch 0 is 0.6582661290322581\n",
            "epoch number is 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 250/2714 [05:47<1:16:57,  1.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 500/2714 [11:35<1:09:02,  1.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 1000/2714 [23:09<1:04:19,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 2000/2714 [46:14<22:12,  1.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2250/2714 [52:02<15:11,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2500/2714 [57:49<06:37,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:02:44<00:00,  1.39s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.7246729919004722      Train Loss: 1.8267665067927839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:28<00:00,  2.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing accuracy after epoch 1 is 0.6771673387096774\n",
            "epoch number is 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 250/2714 [05:47<1:16:36,  1.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  75%|███████▌  | 2042/2714 [47:05<15:27,  1.38s/it]"
          ]
        }
      ],
      "source": [
        "#training\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer1, loss_fn1, 'model_lstm.pth')\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n",
        "    acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "    print(f\"Testing accuracy after epoch {epoch} is {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdOtGo1sd6wj"
      },
      "outputs": [],
      "source": [
        "#testing\n",
        "#testing the model\n",
        "\n",
        "acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "print(f\"Testing Accuracy: {test_acc} \" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4-o1Oq7qUli"
      },
      "source": [
        "###Adding an extra layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHBmSdANqW2k"
      },
      "outputs": [],
      "source": [
        "model = QAModel()\n",
        "model = model.to('cuda')\n",
        "if next(model.parameters()).is_cuda:\n",
        "    print(\"Model is on CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"Model is on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkihMje9qWzR"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-5\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "optimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn1 = nn.CrossEntropyLoss()\n",
        "scheduler = ExponentialLR(optimizer1, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYakBpAdqWws"
      },
      "outputs": [],
      "source": [
        "#training\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer1, loss_fn1, 'model_lstm.pth')\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n",
        "    acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "    print(f\"Testing accuracy after epoch {epoch} is {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jjUY2eWbCN-"
      },
      "source": [
        "###Running it for a different Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiEIsW_Tpy32",
        "outputId": "6e3bac23-d349-42f4-a98b-b5a1b079d35b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on CUDA (GPU).\n"
          ]
        }
      ],
      "source": [
        "model = QAModel()\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "\n",
        "if next(model.parameters()).is_cuda:\n",
        "    print(\"Model is on CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"Model is on CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yToWvHF9-wGx"
      },
      "source": [
        "Training of ADAgrad with these hyperparamters were terrible:\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "\n",
        "Trying some new hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU8aJ0VA-t4K"
      },
      "outputs": [],
      "source": [
        "##Hyperparamters\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFMXjF1hbEvt"
      },
      "outputs": [],
      "source": [
        "##Running the code for SOMETHING instead of Adam\n",
        "optimizer2 = torch.optim.Adagrad(model.parameters(), lr=learning_rate, weight_decay= weight_decay)\n",
        "scheduler = ExponentialLR(optimizer2, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []\n",
        "loss_fn1 = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM5VthPfffiD",
        "outputId": "811e30c5-893e-4cba-c6f4-226d435707b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch number is 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 249/2714 [06:09<1:01:04,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5530625\n",
            "current loss : 3.3280608587265013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :   9%|▉         | 250/2714 [06:13<1:30:36,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 499/2714 [12:22<54:48,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.56578125\n",
            "current loss : 3.236658962011337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  18%|█▊        | 500/2714 [12:30<2:03:37,  3.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 749/2714 [18:39<48:28,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.572875\n",
            "current loss : 3.176421950340271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  28%|██▊       | 750/2714 [18:46<1:41:03,  3.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 999/2714 [24:55<42:13,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.576625\n",
            "current loss : 3.1362219077348708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  37%|███▋      | 1000/2714 [25:00<1:06:46,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  46%|████▌     | 1249/2714 [31:09<36:19,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.57935\n",
            "current loss : 3.106396496772766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  46%|████▌     | 1250/2714 [31:16<1:16:58,  3.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  55%|█████▌    | 1499/2714 [37:25<30:01,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.583125\n",
            "current loss : 3.0666163012186685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  55%|█████▌    | 1500/2714 [37:32<1:04:16,  3.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  64%|██████▍   | 1749/2714 [43:41<23:47,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5855\n",
            "current loss : 3.0386862857001167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  64%|██████▍   | 1750/2714 [43:44<31:38,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 1999/2714 [49:53<17:37,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.587765625\n",
            "current loss : 3.0193292474150657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  74%|███████▎  | 2000/2714 [50:00<36:01,  3.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2249/2714 [56:09<11:28,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5905208333333334\n",
            "current loss : 2.9950792785220677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  83%|████████▎ | 2250/2714 [56:13<18:34,  2.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2499/2714 [1:02:22<05:18,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.59403125\n",
            "current loss : 2.9693413412570955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  92%|█████████▏| 2500/2714 [1:02:25<07:17,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:07:41<00:00,  1.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.5955796333890498      Train Loss: 2.9543759335290884\n",
            "epoch number is 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:07:00<00:00,  1.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.6318579587368905      Train Loss: 2.603548204846126\n",
            "epoch number is 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:07:01<00:00,  1.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.640379743923707      Train Loss: 2.515803294095733\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer2, loss_fn1, 'checkpoint_adagrad.pth',best_acc)\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n",
        "\n",
        "\n",
        "    #if epoch==2:\n",
        "      #val_acc, val_loss = eval_model(model, test_data_loader)\n",
        "      #print(f\"Testing Accuracy: {val_acc}   Testing Loss: {val_loss}\")\n",
        "    # val_acc = eval_model(model, valid_data_loader)\n",
        "    # print(f\"Validation Accuracy: {val_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai3xCGepv80h",
        "outputId": "45074f9a-9a8c-4e31-c7fb-afdf7e5612d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:35<00:00,  1.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.6154233870967742 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#testing the model\n",
        "\n",
        "acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "print(f\"Testing Accuracy: {test_acc} \" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD5y3ErVxENS"
      },
      "source": [
        "###Running a new Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0PtmSj4xJKK",
        "outputId": "55fc4904-4992-4688-ef0f-4d9b119efd69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on CUDA (GPU).\n"
          ]
        }
      ],
      "source": [
        "model = QAModel()\n",
        "#model.load_state_dict(torch.load('checkpoint.pth'))\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "\n",
        "if next(model.parameters()).is_cuda:\n",
        "    print(\"Model is on CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"Model is on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDLuwCW-Hx6n"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbZRP1jAv-sj"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-5\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "optimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "#loss_fn2 = torch.nn.HuberLoss(reduction='none')\n",
        "loss_fn2= FocalLoss(alpha=1, gamma=2, reduction='mean')\n",
        "scheduler = ExponentialLR(optimizer1, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgNdFsUxySdP",
        "outputId": "62ab1c6f-6f5a-40a5-a7ff-08fbdc3e3f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch number is 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 249/2714 [05:53<59:20,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.3053125\n",
            "current loss : 5.263810178756714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :   9%|▉         | 250/2714 [05:57<1:22:03,  2.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 499/2714 [11:56<53:25,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.4175625\n",
            "current loss : 4.0262758972644805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  18%|█▊        | 500/2714 [11:59<1:12:00,  1.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 749/2714 [17:58<47:21,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.470375\n",
            "current loss : 3.4850169452031454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  28%|██▊       | 750/2714 [18:02<1:04:15,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 999/2714 [24:00<41:06,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.502984375\n",
            "current loss : 3.144135613143444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  37%|███▋      | 1000/2714 [24:04<57:03,  2.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  46%|████▌     | 1249/2714 [30:02<35:14,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5267375\n",
            "current loss : 2.9092146228313447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  46%|████▌     | 1250/2714 [30:09<1:14:51,  3.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  55%|█████▌    | 1499/2714 [36:09<29:15,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5425\n",
            "current loss : 2.7489126905202865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  55%|█████▌    | 1500/2714 [36:12<40:02,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  64%|██████▍   | 1749/2714 [42:11<23:14,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5550803571428572\n",
            "current loss : 2.625913234915052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  64%|██████▍   | 1750/2714 [42:14<31:48,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 1999/2714 [48:13<17:11,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5646328125\n",
            "current loss : 2.5274105157256126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  74%|███████▎  | 2000/2714 [48:16<23:28,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2249/2714 [54:16<11:12,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5739236111111111\n",
            "current loss : 2.4399875095420414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  83%|████████▎ | 2250/2714 [54:21<19:54,  2.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2499/2714 [1:00:20<05:10,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.581975\n",
            "current loss : 2.369912795209885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  92%|█████████▏| 2500/2714 [1:00:23<06:52,  1.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:05:31<00:00,  1.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.5872812269745544      Train Loss: 2.313215385114962\n",
            "epoch number is 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 250/2714 [06:02<1:18:24,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 500/2714 [12:04<1:10:35,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 750/2714 [18:10<1:48:29,  3.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 1000/2714 [24:13<57:12,  2.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 2000/2714 [48:17<22:49,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2250/2714 [54:19<15:10,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2500/2714 [1:00:26<11:04,  3.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:05:33<00:00,  1.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.712999723659514      Train Loss: 1.2173944167908097\n",
            "epoch number is 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 250/2714 [06:02<1:18:47,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:05:13<00:00,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.7661039977936334      Train Loss: 0.82389690904887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer1, loss_fn2, 'checkpoint_focal_loss.pth')\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG6TjUtFyfGn",
        "outputId": "434dcd8a-a6b9-4cde-8988-917bf923a91e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:32<00:00,  2.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.671875 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "+#testing the model\n",
        "\n",
        "acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "print(f\"Testing Accuracy: {test_acc} \" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0utuWyj_yDMl"
      },
      "source": [
        "###Freezing certain layers and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0IFkhPqzBEE",
        "outputId": "8d0c8694-234a-4290-a6fb-901af10fb40f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on CUDA (GPU).\n"
          ]
        }
      ],
      "source": [
        "#Freezing certain layers of the model\n",
        "\n",
        "model = QAModel()\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "\n",
        "if next(model.parameters()).is_cuda:\n",
        "    print(\"Model is on CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"Model is on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnq0eWyw0b8N"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-5\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "optimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn1 = nn.CrossEntropyLoss()\n",
        "scheduler = ExponentialLR(optimizer1, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4MynDn80feS",
        "outputId": "5e8e735f-3671-4b2c-9eae-31b1ac7bafdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch number is 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 249/2714 [04:51<48:19,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.233375\n",
            "current loss : 6.646155422210693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :   9%|▉         | 250/2714 [05:11<4:37:09,  6.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 499/2714 [10:05<43:27,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.36128125\n",
            "current loss : 5.246830662727356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  18%|█▊        | 500/2714 [10:09<1:07:16,  1.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 749/2714 [15:03<38:41,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.4215\n",
            "current loss : 4.639446418444315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  28%|██▊       | 750/2714 [15:06<55:18,  1.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 999/2714 [20:00<33:40,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.458890625\n",
            "current loss : 4.266988564968109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  37%|███▋      | 1000/2714 [20:02<47:13,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  46%|████▌     | 1249/2714 [24:56<28:53,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.4844625\n",
            "current loss : 4.014285761928559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  46%|████▌     | 1250/2714 [24:59<41:52,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  55%|█████▌    | 1499/2714 [29:53<23:52,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5032604166666667\n",
            "current loss : 3.8364233899911246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  55%|█████▌    | 1500/2714 [29:56<33:44,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  64%|██████▍   | 1749/2714 [34:50<19:03,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5164196428571428\n",
            "current loss : 3.70632806287493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  64%|██████▍   | 1750/2714 [34:56<39:51,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 1999/2714 [39:50<14:04,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5282734375\n",
            "current loss : 3.590987466216087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  74%|███████▎  | 2000/2714 [39:58<39:47,  3.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2249/2714 [44:52<09:08,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5386527777777778\n",
            "current loss : 3.49022030433019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  83%|████████▎ | 2250/2714 [44:55<13:09,  1.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2499/2714 [49:49<04:14,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.54734375\n",
            "current loss : 3.4097514408111573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  92%|█████████▏| 2500/2714 [49:52<06:23,  1.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [54:04<00:00,  1.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.554444546800988      Train Loss: 3.345319399345246\n",
            "epoch number is 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 250/2714 [04:56<1:09:11,  1.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 750/2714 [14:51<1:28:36,  2.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  55%|█████▌    | 1500/2714 [29:46<1:26:00,  4.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2250/2714 [44:35<13:44,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2500/2714 [49:36<10:21,  2.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [53:48<00:00,  1.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.6795504790021816      Train Loss: 2.1880866339431586\n",
            "epoch number is 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 250/2714 [05:01<1:59:13,  2.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [53:28<00:00,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.7289954863691822      Train Loss: 1.7682625742501517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer1, loss_fn1, 'checkpoint_freeze.pth')\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDykYjoXrUjQ",
        "outputId": "068ad6b1-ae47-4d09-a209-259ee3b8b171"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:26<00:00,  2.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.6633904569892473 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#testing the model\n",
        "\n",
        "acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "print(f\"Testing Accuracy: {test_acc} \" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "O7IsTKuIgUa3",
        "outputId": "6e431df8-a333-4e56-b018-bc7f3fb29263"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot Accuracy\n",
        "plt.plot(total_accuracy, color='blue')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Runs->')\n",
        "plt.title(\"Total Train Accuracy over time\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "t8N3-4oRG3q5",
        "outputId": "b2b11bc3-dc16-4ab5-a610-c1c23a23efaf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAHHCAYAAAB+wBhMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/QklEQVR4nO3dd3wU1f7/8fcmJCEhJKEESCCEUKRKVBBEpSgooCLFQvMalKtXCCIWVNRLEaVZrw3BgoqiKIggFooCglQpIlXE0EF6EgiEfJP5/TG/XQgkIWWzZze8no/HPPbs7GT3s5PRvJlzzozDsixLAAAAXsrPdAEAAAB5IawAAACvRlgBAABejbACAAC8GmEFAAB4NcIKAADwaoQVAADg1QgrAADAqxFWAACAVyOsAF5g4cKFcjgcWrhwoelS1KdPH9WoUcN0GSiE4cOHy+FwmC4DcDvCCi5ZDocjX0t+AsSoUaP0zTff+Ey9nuQMYtOmTTNdSomQlpam4cOHe93vGShOpUwXAJgyefLkbM8/+eQTzZs374L19evXv+h7jRo1Snfeeae6dOnizhKzcWe9eXnvvfeUlZVVpPdA8UlLS9OIESMkSW3atMn22nPPPaenn37aQFVA8SKs4JJ1zz33ZHu+fPlyzZs374L13qKw9aalpSkkJCTfnxMQEFCo+uA+p0+fVmBgoPz8Cnbyu1SpUipViv+to+ShGwjIw8mTJ/X4448rJiZGQUFBqlu3rl5++WWde7Nyh8OhkydP6uOPP3Z1xfTp00eStHPnTvXv319169ZVcHCwKlSooLvuuks7duwolnrbtGmjRo0aafXq1WrVqpVCQkL0zDPPSJJmzpypW2+9VdHR0QoKClKtWrU0cuRIZWZmZnuP88es7NixQw6HQy+//LImTpyoWrVqKSgoSFdffbVWrVrlttr//vtv3XXXXSpfvrxCQkJ0zTXX6LvvvrtguzfffFMNGzZUSEiIypUrp6ZNm2rKlCmu11NTUzVo0CDVqFFDQUFBqlSpkm666SatWbPmojWsXbtWHTt2VFhYmEJDQ9W2bVstX77c9fpvv/0mh8Ohjz/++IKfnTNnjhwOh2bPnu1at3fvXt1///2qXLmygoKC1LBhQ3344YfZfs7ZTfbFF1/oueeeU9WqVRUSEqKUlJQLPmPHjh2KjIyUJI0YMcJ1vA0fPlxSzmNWHA6HBgwYoK+++koNGjRQcHCwWrRooT/++EOSNGHCBNWuXVulS5dWmzZtcjw2V6xYoQ4dOig8PFwhISFq3bq1fv3114vuT8BdiOBALizL0u23364FCxaob9++uuKKKzRnzhwNHjxYe/fu1WuvvSbJ7p7597//rWbNmunBBx+UJNWqVUuStGrVKi1dulQ9evRQtWrVtGPHDo0fP15t2rTRpk2bCnTGI7+OHDmijh07qkePHrrnnntUuXJlSdJHH32k0NBQPfbYYwoNDdXPP/+soUOHKiUlRS+99NJF33fKlClKTU3Vf/7zHzkcDo0bN07dunXT33//XeSzMf/884+uvfZapaWlaeDAgapQoYI+/vhj3X777Zo2bZq6du0qye6iGjhwoO6880498sgjOn36tNavX68VK1aoV69ekqSHHnpI06ZN04ABA9SgQQMdOXJES5Ys0ebNm3XVVVflWsPGjRvVsmVLhYWF6cknn1RAQIAmTJigNm3aaNGiRWrevLmaNm2qmjVr6ssvv1RCQkK2n586darKlSun9u3bu77TNddc4woLkZGR+uGHH9S3b1+lpKRo0KBB2X5+5MiRCgwM1BNPPKH09HQFBgZeUGNkZKTGjx+vfv36qWvXrurWrZskqXHjxnnu38WLF2vWrFlKTEyUJI0ePVq33XabnnzySb3zzjvq37+/jh07pnHjxun+++/Xzz//7PrZn3/+WR07dlSTJk00bNgw+fn5adKkSbrxxhu1ePFiNWvWLM/PBtzCAmBZlmUlJiZa5/4n8c0331iSrBdeeCHbdnfeeaflcDisv/76y7WuTJkyVkJCwgXvmZaWdsG6ZcuWWZKsTz75xLVuwYIFliRrwYIFha7XsiyrdevWliTr3XffzVct//nPf6yQkBDr9OnTrnUJCQlWbGys63lSUpIlyapQoYJ19OhR1/qZM2dakqxvv/02zzqd3+2rr77KdZtBgwZZkqzFixe71qWmplpxcXFWjRo1rMzMTMuyLKtz585Ww4YN8/y88PBwKzExMc9tctKlSxcrMDDQ2r59u2vdvn37rLJly1qtWrVyrRsyZIgVEBCQbV+kp6dbERER1v333+9a17dvXysqKso6fPhwts/p0aOHFR4e7vp9OPdPzZo1c/wdne/QoUOWJGvYsGEXvDZs2LALjglJVlBQkJWUlORaN2HCBEuSVaVKFSslJSXbd5Pk2jYrK8uqU6eO1b59eysrK8u1XVpamhUXF2fddNNNF60XcAe6gYBcfP/99/L399fAgQOzrX/88cdlWZZ++OGHi75HcHCwq52RkaEjR46odu3aioiIyFe3RGEEBQXpvvvuy7OW1NRUHT58WC1btlRaWpq2bNly0fft3r27ypUr53resmVLSXb3TVF9//33atasma6//nrXutDQUD344IPasWOHNm3aJEmKiIjQnj178ux+ioiI0IoVK7Rv3758f35mZqbmzp2rLl26qGbNmq71UVFR6tWrl5YsWeLqlunevbsyMjL09ddfu7abO3eujh8/ru7du0uyz8pNnz5dnTp1kmVZOnz4sGtp3769kpOTL/j9JyQkZPsduVPbtm2zde01b95cknTHHXeobNmyF6x3/k7XrVunbdu2qVevXjpy5IjrO5w8eVJt27bVL7/8wmBseARhBcjFzp07FR0dne1/5tLZ2TY7d+686HucOnVKQ4cOdY15qVixoiIjI3X8+HElJycXS91Vq1bNsQth48aN6tq1q8LDwxUWFqbIyEjX4Nz81FK9evVsz53B5dixY0WueefOnapbt+4F68/f10899ZRCQ0PVrFkz1alTR4mJiReMnRg3bpw2bNigmJgYNWvWTMOHD79ooDp06JDS0tJyrSErK0u7d++WJMXHx6tevXqaOnWqa5upU6eqYsWKuvHGG13vd/z4cU2cOFGRkZHZFmeQPHjwYLbPiYuLy7PGojj/dxceHi5JiomJyXG983e6bds2SXaQOv97vP/++0pPTy+24xg4F2NWgGL08MMPa9KkSRo0aJBatGih8PBwORwO9ejRo9j+RZrTv86PHz+u1q1bKywsTM8//7xq1aql0qVLa82aNXrqqafyVYu/v3+O661zBhsXt/r162vr1q2aPXu2fvzxR02fPl3vvPOOhg4d6prOe/fdd6tly5aaMWOG5s6dq5deekljx47V119/rY4dO7qlju7du+vFF1/U4cOHVbZsWc2aNUs9e/Z0zcRx7s977rnngrEtTuePMymusypS7r+7i/1Ond/jpZde0hVXXJHjtqGhoUUvELgIwgqQi9jYWM2fP1+pqanZzq44u0xiY2Nd63K7aui0adOUkJCgV155xbXu9OnTOn78ePEUnYuFCxfqyJEj+vrrr9WqVSvX+qSkJI/WkZvY2Fht3br1gvU57esyZcqoe/fu6t69u86cOaNu3brpxRdf1JAhQ1S6dGlJdvdN//791b9/fx08eFBXXXWVXnzxxVzDSmRkpEJCQnKtwc/PL9tZiO7du2vEiBGaPn26KleurJSUFPXo0SPb+5UtW1aZmZlq165d4XZKLjx5hVrnQPGwsDC3fw+gIOgGAnJxyy23KDMzU2+99Va29a+99pocDke2P3xlypTJMYD4+/tfcObhzTffvGC6cHFz/gv63FrOnDmjd955x6N15OaWW27RypUrtWzZMte6kydPauLEiapRo4YaNGggyZ7pdK7AwEA1aNBAlmUpIyNDmZmZF3RLVKpUSdHR0UpPT8/18/39/XXzzTdr5syZ2abu/vPPP5oyZYquv/56hYWFudbXr19fl19+uaZOnaqpU6cqKioqWwj09/fXHXfcoenTp2vDhg0XfN6hQ4fyt2Ny4JxB5onA26RJE9WqVUsvv/yyTpw4ccHrRfkeQEFwZgXIRadOnXTDDTfo2Wef1Y4dOxQfH6+5c+dq5syZGjRokOtfnZL9P/X58+fr1VdfVXR0tOLi4tS8eXPddtttmjx5ssLDw9WgQQMtW7ZM8+fPV4UKFTz6Xa699lqVK1dOCQkJGjhwoBwOhyZPnuzRLpzp06fnOJA3ISFBTz/9tD7//HN17NhRAwcOVPny5fXxxx8rKSlJ06dPd10c7eabb1aVKlV03XXXqXLlytq8ebPeeust3XrrrSpbtqyOHz+uatWq6c4771R8fLxCQ0M1f/58rVq1KtvZrZy88MILmjdvnq6//nr1799fpUqV0oQJE5Senq5x48ZdsH337t01dOhQlS5dWn379r3gAm5jxozRggUL1Lx5cz3wwANq0KCBjh49qjVr1mj+/Pk6evRoofZjcHCwGjRooKlTp+qyyy5T+fLl1ahRIzVq1KhQ75cXPz8/vf/+++rYsaMaNmyo++67T1WrVtXevXu1YMEChYWF6dtvv3X75wIXMDYPCfAyOU0FTk1NtR599FErOjraCggIsOrUqWO99NJL2aZxWpZlbdmyxWrVqpUVHBxsSXJNYz527Jh13333WRUrVrRCQ0Ot9u3bW1u2bLFiY2OzTXV259Tl3Kb2/vrrr9Y111xjBQcHW9HR0daTTz5pzZkz54LPzW3q8ksvvXTBeyqXKbTncn633BbndOXt27dbd955pxUREWGVLl3aatasmTV79uxs7zVhwgSrVatWVoUKFaygoCCrVq1a1uDBg63k5GTLsuwpxIMHD7bi4+OtsmXLWmXKlLHi4+Otd955J88andasWWO1b9/eCg0NtUJCQqwbbrjBWrp0aY7bbtu2zfUdlixZkuM2//zzj5WYmGjFxMRYAQEBVpUqVay2bdtaEydOvGD/5DW1+3xLly61mjRpYgUGBmb7HeQ2dfn8qdy5/U5zq2Xt2rVWt27dXPs9NjbWuvvuu62ffvop3zUDReGwLA/+0woAAKCAGLMCAAC8GmEFAAB4NcIKAADwaoQVAADg1QgrAADAqxFWAACAV/Ppi8JlZWVp3759Klu2rEcvQQ0AAArPsiylpqYqOjr6ggsq5sSnw8q+ffsuuGsoAADwDbt371a1atUuup1PhxXnzeV2796d7b4dAADAe6WkpCgmJibbTWLz4tNhxdn1ExYWRlgBAMDH5HcIBwNsAQCAVyOsAAAAr0ZYAQAAXo2wAgAAvBphBQAAeDXCCgAA8GqEFQAA4NUIKwAAwKsRVgAAgFcjrAAAAK9GWAEAAF6NsAIAALwaYSUnliXt3Stt3266EgAALnmElZy8845UrZr0+OOmKwEA4JJHWMlJ3br24+bNZusAAACElRzVr28/bt8upaebrQUAgEscYSUn0dFS2bJSZqa0bZvpagAAuKQRVnLicEgNGthtuoIAADCKsJIbZ1cQYQUAAKMIK7lxhpVNm8zWAQDAJY6wkhu6gQAA8AqEldw4z6xs3WoPtAUAAEYQVnJTo4YUFGRPXU5KMl0NAACXLMJKbvz9pXr17DZdQQAAGENYyQszggAAMI6wkhfCCgAAxhFW8sL0ZQAAjCOs5OXc6cuWZbYWAAAuUYSVvNSpYw+0TU2V9u0zXQ0AAJckwkpeAgOlWrXsNl1BAAAYQVi5GK5kCwCAUYSVi2FGEAAARhFWLoYZQQAAGEVYuRi6gQAAMIqwcjHOS+4fOiQdOWK2FgAALkGElYspU0aqXt1uc3YFAACPI6zkh7MriHErAAB4HGElP5gRBACAMYSV/CCsAABgDGElP+gGAgDAGMJKfjjPrOzeLZ04YbYWAAAuMYSV/ChfXqpUyW5v2WK2FgAALjGElfziSrYAABhBWMkvrmQLAIARhJX8YkYQAABGEFbyi24gAACMIKzkl7MbaPt2KT3dbC0AAFxCCCv5FRUlhYVJWVnStm2mqwEA4JJBWMkvh4NxKwAAGEBYKQiuZAsAgMcRVgqCMysAAHgcYaUgCCsAAHgcYaUgnN1AW7dKmZlmawEA4BJBWCmI2FipdGl76nJSkulqAAC4JBgPK3v37tU999yjChUqKDg4WJdffrl+++0302XlzN9fqlvXbtMVBACARxgNK8eOHdN1112ngIAA/fDDD9q0aZNeeeUVlStXzmRZeWNGEAAAHlXK5IePHTtWMTExmjRpkmtdXFycwYrygUG2AAB4lNEzK7NmzVLTpk111113qVKlSrryyiv13nvv5bp9enq6UlJSsi0eR1gBAMCjjIaVv//+W+PHj1edOnU0Z84c9evXTwMHDtTHH3+c4/ajR49WeHi4a4mJifFwxcoeVizL858PAMAlxmFZ5v7iBgYGqmnTplq6dKlr3cCBA7Vq1SotW7bsgu3T09OVfs5NBFNSUhQTE6Pk5GSFhYV5pGadOSOFhNhTl3fvlqpV88znAgBQQqSkpCg8PDzff7+NnlmJiopSA+eA1f+vfv362rVrV47bBwUFKSwsLNvicYGBUu3adpuuIAAAip3RsHLddddp69at2db9+eefio2NNVRRPjFuBQAAjzEaVh599FEtX75co0aN0l9//aUpU6Zo4sSJSkxMNFnWxTF9GQAAjzEaVq6++mrNmDFDn3/+uRo1aqSRI0fq9ddfV+/evU2WdXGcWQEAwGOMXmdFkm677TbddtttpssoGMIKAAAeY/xy+z6pXj378dAh6fBhs7UAAFDCEVYKo0wZ+6aGEmdXAAAoZoSVwqIrCAAAjyCsFBYzggAA8AjCSmFxZgUAAI8grBQWYQUAAI8grBSWM6zs3i2lppqtBQCAEoywUljly0uVK9vtLVvM1gIAQAlGWCkKuoIAACh2hJWiIKwAAFDsCCtFwfRlAACKHWGlKDizAgBAsSOsFIUzrGzfLqWnm60FAIASirBSFFFRUni4lJUl/fmn6WoAACiRCCtF4XDQFQQAQDEjrBQVYQUAgGJFWCkqZgQBAFCsCCtFxZkVAACKFWGlqJxh5c8/pcxMs7UAAFACEVaKKjZWCg62py4nJZmuBgCAEoewUlT+/lLdunabcSsAALgdYcUdGLcCAECxIay4g3NGEGEFAAC3I6y4g/PMCt1AAAC4HWHFHZxhZcsWybLM1gIAQAlDWHGH2rXtgbapqdLevaarAQCgRCGsuENgoFSnjt2mKwgAALcirLgLM4IAACgWhBV3IawAAFAsCCvuwvRlAACKBWHFXZi+DABAsSCsuIvzkvuHD9sLAABwC8KKu5QpI9WoYbfpCgIAwG0IK+5EVxAAAG5HWHEnZgQBAOB2hBV3YkYQAABuR1hxJ7qBAABwO8KKOznDyp499n2CAABAkRFW3KlcOalKFbu9ZYvZWgAAKCEIK+5GVxAAAG5FWHE3ZgQBAOBWhBV3I6wAAOBWhBV3Y/oyAABuRVhxN+eZle3bpdOnzdYCAEAJQFhxtypVpPBwKStL2rbNdDUAAPg8woq7ORzSFVfY7fnzjZYCAEBJQFgpDt27248ff2y2DgAASgDCSnHo3l0KDJR+/11at850NQAA+DTCSnEoX166/Xa7zdkVAACKhLBSXBIS7MfPPpMyMszWAgCADyOsFJf27aVKlaRDh6QffzRdDQAAPouwUlwCAqR77rHbdAUBAFBohJXi5OwKmjVLOnLEbC0AAPgowkpxatzYvuZKRob0xRemqwEAwCcRVoqb8+wKXUEAABQKYaW49eollSolrVrFzQ0BACgEwkpxq1RJuuUWu83ZFQAACoyw4gnOrqDJk6XMTLO1AADgY4yGleHDh8vhcGRb6tWrZ7Kk4nHrrfZVbfft4+aGAAAUkPEzKw0bNtT+/ftdy5IlS0yX5H5BQVLPnnabriAAAArEeFgpVaqUqlSp4loqVqxouqTi4ewKmjFDSk42WwsAAD7EeFjZtm2boqOjVbNmTfXu3Vu7du3Kddv09HSlpKRkW3xG06ZSgwbS6dPSV1+ZrgYAAJ9hNKw0b95cH330kX788UeNHz9eSUlJatmypVJTU3PcfvTo0QoPD3ctMTExHq64CBwOrrkCAEAhOCzLskwX4XT8+HHFxsbq1VdfVd++fS94PT09Xenp6a7nKSkpiomJUXJyssLCwjxZauHs2yfFxEhZWdK2bVLt2qYrAgDA41JSUhQeHp7vv9/Gu4HOFRERocsuu0x//fVXjq8HBQUpLCws2+JToqOlm26y2598YrYWAAB8hFeFlRMnTmj79u2KiooyXUrxcXYFffKJfYYFAADkyWhYeeKJJ7Ro0SLt2LFDS5cuVdeuXeXv76+ezmm+JVGXLlJYmLRzp/TLL6arAQDA6xkNK3v27FHPnj1Vt25d3X333apQoYKWL1+uyMhIk2UVr+BgqXt3u81AWwAALsqrBtgWVEEH6HiNX3+Vrr9eKlNGOnBACg01XREAAB7j0wNsLxnXXmvPBDp5Uvr6a9PVAADg1QgrJjgc0r332m26ggAAyBNhxZR//ct+XLBAyuOqvQAAXOoIK6bUqCHdcINkWdLkyaarAQDAaxFWTDr38vu+O84ZAIBiRVgx6Y477BlB27ZJy5aZrgYAAK9EWDEpNNQOLBIDbQEAyAVhxTRnV9DUqdKpU2ZrAQDACxFWTGvTRqpeXUpOlmbNMl0NAABeh7Bimp/f2WuufPSR0VIAAPBGhBVv4Awrc+dK+/aZrQUAAC9DWPEGderYl+DPypI++8x0NQAAeBXCirfgmisAAOSIsOIt7r5bKl1a2rhRWrPGdDUAAHgNwoq3iIiQunSx2wy0BQDAhbDiTZxdQZ9/Lp05Y7YWAAC8BGHFm9x0kxQVJR05In33nelqAADwCoQVb+LvL91zj93+4AOztQAA4CUIK96mb1/7QnHffSfNn2+6GgAAjCOseJu6daXERLudmCilp5utBwAAwwgr3mjkSKlyZenPP6VXXjFdDQAARhFWvFF4+NmQ8sIL0o4dRssBAMAkwoq36tXLviPzqVPSoEGmqwEAwBjCirdyOKS335ZKlZJmzpRmzzZdEQAARhBWvFmDBtKjj9rtgQPtsywAAFxiCCvebuhQqVo1KSlJGj3adDUAAHgcYcXbhYZKr79ut8eOlbZtM1oOAACeRljxBd26Se3b2/cLevhhybJMVwQAgMcQVnyBwyG9+aYUGCjNmSN9/bXpigAA8BjCiq+oU0d66im7PWiQdOKE0XIAAPAUwoovGTJEiouT9uyRnn/edDUAAHgEYcWXBAdLb7xht197Tdq40Ww9AAB4AGHF19x2m9S5s/R//2ff6JDBtgCAEo6w4ov+9z/7LMuiRdKUKaarAQCgWBFWfFFsrPTcc3b78cel5GSz9QAAUIwIK77q8celyy6T/vnHvsotAAAlVKHCyu7du7Vnzx7X85UrV2rQoEGaOHGi2wrDRQQF2Tc6lKS33pLWrjVbDwAAxaRQYaVXr15asGCBJOnAgQO66aabtHLlSj377LN6nim1ntOundS9u5SVJfXvbz8CAFDCFCqsbNiwQc2aNZMkffnll2rUqJGWLl2qzz77TB999JE768PFvPKKff+g5culSZNMVwMAgNsVKqxkZGQoKChIkjR//nzdfvvtkqR69epp//797qsOF1e1qjRihN1+6inpyBGz9QAA4GaFCisNGzbUu+++q8WLF2vevHnq0KGDJGnfvn2qUKGCWwtEPjz8sNSokR1UnnnGdDUAALhVocLK2LFjNWHCBLVp00Y9e/ZUfHy8JGnWrFmu7iF4UECANH683X7vPWnFCrP1AADgRg7LKtwlUDMzM5WSkqJy5cq51u3YsUMhISGqVKmS2wrMS0pKisLDw5WcnKywsDCPfKZX69NH+vhj6aqrpJUrJX9/0xUBAHCBgv79LtSZlVOnTik9Pd0VVHbu3KnXX39dW7du9VhQQQ7GjZMiIqQ1a6RnnzVdDQAAblGosNK5c2d98sknkqTjx4+refPmeuWVV9SlSxeNd3ZHwPMqVbKvuSJJY8eebQMA4MMKFVbWrFmjli1bSpKmTZumypUra+fOnfrkk0/0hvOuwDCjd2/phRfs9sCB0rRpZusBAKCIChVW0tLSVLZsWUnS3Llz1a1bN/n5+emaa67Rzp073VogCuGZZ+yLxFmWdM890i+/mK4IAIBCK1RYqV27tr755hvt3r1bc+bM0c033yxJOnjwIANdvYHDIb3xhtSli5SeLt1+u7Rhg+mqAAAolEKFlaFDh+qJJ55QjRo11KxZM7Vo0UKSfZblyiuvdGuBKCR/f2nKFOm66+y7MnfoIO3ebboqAAAKrNBTlw8cOKD9+/crPj5efn525lm5cqXCwsJUr149txaZG6Yu58PRo9L110ubN0sNG0qLF0vnTDcHAMDTCvr3u9Bhxcl59+Vq1aoV5W0KhbCST7t2SS1aSPv2Sa1aSXPmSKVLm64KAHCJ8sh1VrKysvT8888rPDxcsbGxio2NVUREhEaOHKks7vzrfapXl378UQoLswfb3nOPlJlpuioAAPKlUGHl2Wef1VtvvaUxY8Zo7dq1Wrt2rUaNGqU333xT//3vf91dI9zh8sulmTOlwEBp+nRp0CB7thAAAF6uUN1A0dHRevfdd113W3aaOXOm+vfvr71797qtwLzQDVQIX34pde9ut0ePlp5+2mw9AIBLjke6gY4ePZrjINp69erp6NGjhXlLeMrdd0uvvWa3hwyR/v+ViAEA8FaFCivx8fF6K4dLub/11ltq3LhxkYtCMRs0SHriCbvdt6894BYAAC9VqjA/NG7cON16662aP3++6xory5Yt0+7du/X999+7tUAUk7Fjpf37pc8+k+64Q1q0SGrSxHRVAABcoFBnVlq3bq0///xTXbt21fHjx3X8+HF169ZNGzdu1OTJk91dI4qDn5/04YdSu3bSyZPSLbdI27ebrgoAgAsU+Tor5/r999911VVXKbMQ02LHjBmjIUOG6JFHHtHrr7+er59hgK0bpKRIrVtL69ZJtWtLv/5q370ZAIBi4pEBtu62atUqTZgwgfEuJoSFSd9/L9WoIf31l3TbbdKJE6arAgDAxXhYOXHihHr37q333ntP5bgMvBlRUfZF4ypUkFatsm+AeOyY6aoAAJDkBWElMTFRt956q9q1a3fRbdPT05WSkpJtgZvUrSvNni2FhEg//SQ1bSr9/rvpqgAAKNhsoG7duuX5+vHjxwv04V988YXWrFmjVatW5Wv70aNHa8SIEQX6DBTANddIS5ZI3bpJf/9t30/ovfek3r1NVwYAuIQV6MxKeHh4nktsbKzuvffefL3X7t279cgjj+izzz5T6XzeVG/IkCFKTk52Lbt37y5I+ciPK6+UVq+W2reXTp2y7yP0yCNSRobpygAAlyi3zgYqiG+++UZdu3aVv7+/a11mZqYcDof8/PyUnp6e7bWcMBuoGGVmSsOHSy+8YD9v2dK+VH+VKkbLAgD4voL+/TYWVlJTU7Vz585s6+677z7Vq1dPTz31lBo1anTR9yCseMDMmdK999pTnKOipGnTpGuvNV0VAMCHFfTvd6GuYOsOZcuWvSCQlClTRhUqVMhXUIGHdO5szxDq2lXatElq00Z6/XWpXz/J4TBdHQDgEmB8NhB8wGWXSStWSHfdZY9dSUyU+vSxx7QAAFDMjHUDuQPdQB5mWdKrr0pPPillZdmDcadPl+LiTFcGAPAhPnkFW/gIh0N6/HFp3jypYkVp7Vr7eixz55quDABQghFWUHA33iitWSNdfbV09KjUoYM0apR9tgUAADcjrKBwYmKkX36RHnjA7h569lnpjjvsWUMAALgRYQWFV7q0NHGifZXbwEDpm2/ssy3Ll5uuDABQghBWUHT//re0eLFUrZr055/2Zfr/9S9p717TlQEASgDCCtyjWTN7HMv999sDcT/91J7yPHIkU5wBAEVCWIH7REZKH3xgX0TuuuuktDRp6FCpfn3pq6/ssS0AABQQYQXu16SJ3S30+ed219DOndLdd0utW9vTnQEAKADCCoqHwyH16CFt3WrfEDE42A4wTZrYM4j++cd0hQAAH0FYQfEKCZGGDbNDS8+edlfQ++9LdepIL78snTljukIAgJcjrMAzYmKkKVOkJUvssyupqdLgwVLDhtK33zKeBQCQK8IKPOu666SVK6UPP5QqV5b++ku6/XapfXtp40bT1QEAvBBhBZ7n5yfdd599TZannrIvKDdvnhQfb9/Ref9+0xUCALwIYQXmhIVJY8ZImzZJXbpImZnSO+9INWvaN0w8eNB0hQAAL0BYgXm1akkzZkg//yxde610+rT06qtSXJz09NPSkSOmKwQAGERYgfe44QZ7AO6PP9r3GEpLk8aOtUPL0KHS8eOmKwQAGEBYgXdxOOzBtitWSLNmSVdcYc8cGjlSqlHDfuTOzgBwSSGswDs5HFKnTtLq1dL06VKjRlJysn2GJS7OPuNy8qTpKgEAHkBYgXfz85O6dZN+/92+fH/dutLRo/ZYlrg4e2wLN0oEgBKNsALf4OdnX75/wwbpk0/sQbmHDtmzhmrVkt56S0pPN10lAKAYEFbgW0qVkv71L2nzZvuy/bGx9nVZHn7YvoT///5nj3EBAJQYhBX4poAAqW9f+8Jy48dLVatKu3dLgwbZl/Z/8kn7OQDA5xFW4NsCA6WHHrIv2//uu/aYluRk6aWX7DEtvXpJv/1mukoAQBEQVlAylC4t/ec/9tVwZ8+2r9mSmWkPyr36aql1a2nmTHsdAMCnEFZQsvj5Sbfeal8Nd80ae3xLqVLSL7/Yl/SvV096+22mPQOADyGsoOS68kp75tCOHdKQIVK5cnZ30YAB9riWZ56R9u0zXSUA4CIIKyj5qlaVRo2yB9y+9ZZUu7Z07Jg0erR9Vdx775XWrTNdJQAgF4QVXDrKlJESE6UtW6RvvpFatpQyMqTJk+2zMK1bSx98wD2IAMDLEFZw6fH3lzp3tsexrFwp9expr/vlF+nf/5aqVJHuuMO+EzQXmgMA4xyWZVmmiyislJQUhYeHKzk5WWFhYabLgS/bs0f69FN72bjx7PqICOnOO6XevaVWrewBvACAIino32/CCnAuy5LWr5c++0yaMkXau/fsazEx9lmY3r2lxo3N1QgAPo6wArhLVpbdNfTpp9K0afbF5pwaNbJDS69eUvXq5moEAB9EWAGKw+nT0vff28Hlu++kM2fOvtaqlR1c/vUvKTjYXI0A4CMIK0BxO3ZMmj7d7ipauPDs+gcflCZMMFYWAPiKgv79ZrQgUFDlytmzhhYskHbtkh591F6/eLHZugCghCKsAEUREyMNHmy3t26V0tLM1gMAJRBhBSiqKlWkSpXsAbl//GG6GgAocQgrQFE5HPYVcCUu2w8AxYCwArjDFVfYj2vXGi0DAEoiwgrgDs6wwpkVAHA7wgrgDs5uoPXrpcxMs7UAQAlDWAHcoXZtKSREOnVK+vNP09UAQIlCWAHcwd9fio+323QFAYBbEVYAd2GQLQAUC8IK4C5MXwaAYkFYAdzl3DMrvnvLLQDwOoQVwF0aNbLHrhw+LO3bZ7oaACgxCCuAuwQHS/Xq2W26ggDAbQgrgDsxyBYA3I6wArgTg2wBwO0IK4A7cWYFANyOsAK4kzOs/P23lJxstBQAKCkIK4A7VaggxcTY7fXrzdYCACUEYQVwN7qCAMCtCCuAuzHIFgDcirACuBtnVgDArQgrgLs5w8rGjdKZM0ZLAYCSgLACuFuNGlJ4uJSRIW3ebLoaAPB5RsPK+PHj1bhxY4WFhSksLEwtWrTQDz/8YLIkoOgcDrqCAMCNjIaVatWqacyYMVq9erV+++033XjjjercubM2btxosiyg6BhkCwBuU8rkh3fq1Cnb8xdffFHjx4/X8uXL1bBhQ0NVAW7AmRUAcBujYeVcmZmZ+uqrr3Ty5Em1aNEix23S09OVnp7uep6SkuKp8oCCOffMimXZXUMAgEIxPsD2jz/+UGhoqIKCgvTQQw9pxowZatCgQY7bjh49WuHh4a4lxnmlUMDb1KsnBQZKKSnSjh2mqwEAn2Y8rNStW1fr1q3TihUr1K9fPyUkJGjTpk05bjtkyBAlJye7lt27d3u4WiCfAgMlZ1cmXUEAUCTGw0pgYKBq166tJk2aaPTo0YqPj9f//ve/HLcNCgpyzRxyLoDXYpAtALiF8bByvqysrGzjUgCfxSBbAHALowNshwwZoo4dO6p69epKTU3VlClTtHDhQs2ZM8dkWYB7cGYFANzCaFg5ePCg7r33Xu3fv1/h4eFq3Lix5syZo5tuuslkWYB7NG5sP+7ZIx0+LFWsaLYeAPBRRsPKBx98YPLjgeIVFibVqiVt326fXWnXznRFAOCTvG7MClCi0BUEAEVGWAGKE4NsAaDICCtAceLMCgAUGWEFKE7OMytbtkhpaUZLAQBfRVgBilNUlBQZKWVlSRs2mK4GAHwSYQUoTg4HXUEAUESEFaC4McgWAIqEsAIUN86sAECREFaA4uY8s7J+vZSZabQUAPBFhBWguNWpI4WE2LOBtm0zXQ0A+BzCClDc/P3P3ieIriAAKDDCCuAJDLIFgEIjrACewCBbACg0wgrgCeeeWbEso6UAgK8hrACecPnlkp+fdOiQtH+/6WoAwKcQVgBPCA6W6tWz23QFAUCBEFYAT2GQLQAUCmEF8BQG2QJAoRBWAE/hzAoAFAphBfAUZ1jZvl1KSTFaCgD4EsIK4CkVK0rVqtnt9evN1gIAPoSwAngSXUEAUGCEFcCTGGQLAAVGWAE8iTMrAFBghBXAk5xnVjZulM6cMVsLAPgIwgrgSTVqSOHhdlDZssV0NQDgEwgrgCc5HHQFAUABEVYAT3OGFQbZAkC+EFYAT+PMCgAUCGEF8LRzpy9bltFSAMAXEFYAT6tfXwoIkJKTpZ07TVcDAF6PsAJ4WmCg1KiR3aYrCAAuirACmMAgWwDIN8IKYAKDbAEg3wgrgAncIwgA8o2wApgQH28/7t4tHTlithYA8HKEFcCEsDCpVi27zdkVAMgTYQUwhUG2AJAvhBXAFAbZAkC+EFYAUxhkCwD5QlgBTHGeWdmyRTp1ymgpAODNCCuAKdHRUmSklJkpbdhguhoA8FqEFcAUh4NBtgCQD4QVwCTnuJXCDrI9c0bavt2+Xsvp0+6rCwC8SCnTBQCXtPycWTl2TPr7bzuUbN9+tv3333ZIyco6u21oqN21FBkpVap0tp3bUqZMcX47AHALwgpgkjOs/P67tGBB9jDibB87lvd7lC4t/d//2cuJE/aSlJS/zw8OlsqVk/z9JT+/7EtO63J6vVQp+07SAQH2Y0HaQUFSSIi9lClzdjn3eUiIXacfJ4KBSxVhBTDpssvsP8RpadKNN+a+XZUqUs2a9lVva9U6265ZU6pc2d7m+HHp0KH8L+np9iwkX5mJdH6oCQmxQ09egcrhyPv1gICzy7lhKj/rSpe2f3fOMHXuo7Ndiv/FAu7Af0mASf7+Up8+0ocfStWrZw8iznbNmvnrrilXzl4uu+zi21qWfQbm0CEpOdnuSnIumZnZn5+/nPt6ZqZ9Ricjwx4/c+ZMwdrp6XZQO3nSXs5vnxuk0tLs5fDhQu9ujwsIuDDAOB/zCkIXa9evL7Vvb/rbAR7jsCzLMl1EYaWkpCg8PFzJyckKCwszXQ5QeJZlnwVAdllZZ0NKToEmI8PexrJyD1e5veYMWueGp4yM7O3cXnMGrVOnzoaqcx894ZdfpJYtPfNZgJsV9O83Z1YAb0BQyZmfnz1oODTUdCX5Z1n2zKzzA8z5oSavkJRXeNq4UVq9WhoyRFq8mGMHlwTCCgC4k8Nhd/MEB0vly7v//fftk2rXln79VfruO+m229z/GYCXYXg9APiS6GjpkUfs9pAhdncWUMIRVgDA1zz5pBQRYd+mYcoU09UAxY6wAgC+plw56emn7fbQofZgX6AEI6wAgC96+GEpKkrasUOaONF0NUCxIqwAgC8KCZGGDbPbI0dKqalm6wGKEWEFAHzV/fdLderYF/d77TXT1QDFhrACAL4qIEB64QW7/fLLdmgBSiCjYWX06NG6+uqrVbZsWVWqVEldunTR1q1bTZYEAL7lzjulq66yu4FGjzZdDVAsjIaVRYsWKTExUcuXL9e8efOUkZGhm2++WSdPnjRZFgD4Dj+/syHl7belXbvM1gMUA6+6N9ChQ4dUqVIlLVq0SK1atbro9twbCABkX+K/bVtpwQLpvvvsG2MCXqygf7+9asxKcnKyJKl8LpeoTk9PV0pKSrYFAC55Doc0Zozd/vhjadMms/UAbuY1YSUrK0uDBg3Sddddp0aNGuW4zejRoxUeHu5aYmJiPFwlAHipZs2kbt3sO0o/+6zpagC38ppuoH79+umHH37QkiVLVK1atRy3SU9PV/o5V2pMSUlRTEwM3UAAIEmbN0uNGtmBZdky6ZprTFcE5Mgnu4EGDBig2bNna8GCBbkGFUkKCgpSWFhYtgUA8P/Vry/16WO3n37aHssClABGw4plWRowYIBmzJihn3/+WXFxcSbLAQDfN3y4FBQkLVokzZljuhrALYyGlcTERH366aeaMmWKypYtqwMHDujAgQM6deqUybIAwHfFxEgDBtjtIUPsLiHAxxkds+JwOHJcP2nSJPVxnsrMA1OXASAHR45INWtKKSnS559LPXqYrgjIxqfGrFiWleOSn6ACAMhFhQrS4MF2+7nnpIwMs/UAReQVA2wBAG42aJBUubK0fbv0/vumqwGKhLACACVRaKj03//a7eefl7iNCXwYYQUASqoHHpDi4qQDB6Q33jBdDVBohBUAKKkCA6WRI+322LHS0aNm6wEKibACACVZz55S48ZScrIdWAAfRFgBgJLMz08aNcpuv/GGtGeP2XqAQihlugAAQDG75RapZUtp8WJ7sO3EiXlvf+KEtH+/PdblwIGz7f37pVOnpIoVpUqVpMhI+/HcdkSEHZAANyKsAEBJ53BIo0dL118vffih1Lq1lJ6ePYic2y7KzKFSpXIPM5GRdi2nT9uh59Sps+3zH3Nad+aMHYT8/e3H3Nq5vX7+4nAU7HlAgD0O6NzHnNbl9OjnZ9+ryblIeT8/d52U+3fI6fvl9p3P/T7Odk7rzn89NNT+nRrkNXddLgyuYAsABXD77dK33+Zv25AQKSrKXqpUsZeoKHv94cPSwYPSoUPZH5OTi7d+mNGzpzRlilvfsqB/vzmzAgCXildescesWNbZ8HFuEDm3HRpa8PdPT889yBw6ZC+SFBwslS5d8MfAQLv2zEz7nkfOx3PbOa07t21ZZ9cVpJ2ZaV8JOCPDPsNz/mNO6859zXlewOG4cLnYeil7Ted/t4utz8w8+/M5fbeLffegoKIdd25AWAGAS0WdOtKaNcX3/kFBUtWq9gK4EaOgAACAVyOsAAAAr0ZYAQAAXo2wAgAAvBphBQAAeDXCCgAA8GqEFQAA4NUIKwAAwKsRVgAAgFcjrAAAAK9GWAEAAF6NsAIAALwaYQUAAHg1wgoAAPBqpUwXUBSWZUmSUlJSDFcCAADyy/l32/l3/GJ8OqykpqZKkmJiYgxXAgAACio1NVXh4eEX3c5h5TfWeKGsrCzt27dPZcuWlcPhcOt7p6SkKCYmRrt371ZYWJhb37ukYp8VDvutcNhvhcN+Kzj2WeHktd8sy1Jqaqqio6Pl53fxESk+fWbFz89P1apVK9bPCAsL4+AsIPZZ4bDfCof9Vjjst4JjnxVObvstP2dUnBhgCwAAvBphBQAAeDXCSi6CgoI0bNgwBQUFmS7FZ7DPCof9Vjjst8JhvxUc+6xw3LnffHqALQAAKPk4swIAALwaYQUAAHg1wgoAAPBqhBUAAODVCCs5ePvtt1WjRg2VLl1azZs318qVK02X5NWGDx8uh8ORbalXr57psrzOL7/8ok6dOik6OloOh0PffPNNttcty9LQoUMVFRWl4OBgtWvXTtu2bTNTrBe52H7r06fPBcdfhw4dzBTrJUaPHq2rr75aZcuWVaVKldSlSxdt3bo12zanT59WYmKiKlSooNDQUN1xxx36559/DFXsHfKz39q0aXPB8fbQQw8Zqti88ePHq3Hjxq4Lv7Vo0UI//PCD63V3HWeElfNMnTpVjz32mIYNG6Y1a9YoPj5e7du318GDB02X5tUaNmyo/fv3u5YlS5aYLsnrnDx5UvHx8Xr77bdzfH3cuHF644039O6772rFihUqU6aM2rdvr9OnT3u4Uu9ysf0mSR06dMh2/H3++ecerND7LFq0SImJiVq+fLnmzZunjIwM3XzzzTp58qRrm0cffVTffvutvvrqKy1atEj79u1Tt27dDFZtXn72myQ98MAD2Y63cePGGarYvGrVqmnMmDFavXq1fvvtN914443q3LmzNm7cKMmNx5mFbJo1a2YlJia6nmdmZlrR0dHW6NGjDVbl3YYNG2bFx8ebLsOnSLJmzJjhep6VlWVVqVLFeumll1zrjh8/bgUFBVmff/65gQq90/n7zbIsKyEhwercubORenzFwYMHLUnWokWLLMuyj62AgADrq6++cm2zefNmS5K1bNkyU2V6nfP3m2VZVuvWra1HHnnEXFE+oFy5ctb777/v1uOMMyvnOHPmjFavXq127dq51vn5+aldu3ZatmyZwcq837Zt2xQdHa2aNWuqd+/e2rVrl+mSfEpSUpIOHDiQ7dgLDw9X8+bNOfbyYeHChapUqZLq1q2rfv366ciRI6ZL8irJycmSpPLly0uSVq9erYyMjGzHW7169VS9enWOt3Ocv9+cPvvsM1WsWFGNGjXSkCFDlJaWZqI8r5OZmakvvvhCJ0+eVIsWLdx6nPn0jQzd7fDhw8rMzFTlypWzra9cubK2bNliqCrv17x5c3300UeqW7eu9u/frxEjRqhly5basGGDypYta7o8n3DgwAFJyvHYc76GnHXo0EHdunVTXFyctm/frmeeeUYdO3bUsmXL5O/vb7o847KysjRo0CBdd911atSokST7eAsMDFRERES2bTnezsppv0lSr169FBsbq+joaK1fv15PPfWUtm7dqq+//tpgtWb98ccfatGihU6fPq3Q0FDNmDFDDRo00Lp169x2nBFWUGQdO3Z0tRs3bqzmzZsrNjZWX375pfr27WuwMlwKevTo4Wpffvnlaty4sWrVqqWFCxeqbdu2BivzDomJidqwYQPjyAoot/324IMPutqXX365oqKi1LZtW23fvl21atXydJleoW7dulq3bp2Sk5M1bdo0JSQkaNGiRW79DLqBzlGxYkX5+/tfMFL5n3/+UZUqVQxV5XsiIiJ02WWX6a+//jJdis9wHl8ce0VXs2ZNVaxYkeNP0oABAzR79mwtWLBA1apVc62vUqWKzpw5o+PHj2fbnuPNltt+y0nz5s0l6ZI+3gIDA1W7dm01adJEo0ePVnx8vP73v/+59TgjrJwjMDBQTZo00U8//eRal5WVpZ9++kktWrQwWJlvOXHihLZv366oqCjTpfiMuLg4ValSJduxl5KSohUrVnDsFdCePXt05MiRS/r4syxLAwYM0IwZM/Tzzz8rLi4u2+tNmjRRQEBAtuNt69at2rVr1yV9vF1sv+Vk3bp1knRJH2/ny8rKUnp6unuPM/eOAfZ9X3zxhRUUFGR99NFH1qZNm6wHH3zQioiIsA4cOGC6NK/1+OOPWwsXLrSSkpKsX3/91WrXrp1VsWJF6+DBg6ZL8yqpqanW2rVrrbVr11qSrFdffdVau3attXPnTsuyLGvMmDFWRESENXPmTGv9+vVW586drbi4OOvUqVOGKzcrr/2WmppqPfHEE9ayZcuspKQka/78+dZVV11l1alTxzp9+rTp0o3p16+fFR4ebi1cuNDav3+/a0lLS3Nt89BDD1nVq1e3fv75Z+u3336zWrRoYbVo0cJg1eZdbL/99ddf1vPPP2/99ttvVlJSkjVz5kyrZs2aVqtWrQxXbs7TTz9tLVq0yEpKSrLWr19vPf3005bD4bDmzp1rWZb7jjPCSg7efPNNq3r16lZgYKDVrFkza/ny5aZL8mrdu3e3oqKirMDAQKtq1apW9+7drb/++st0WV5nwYIFlqQLloSEBMuy7OnL//3vf63KlStbQUFBVtu2ba2tW7eaLdoL5LXf0tLSrJtvvtmKjIy0AgICrNjYWOuBBx645P9xkdP+kmRNmjTJtc2pU6es/v37W+XKlbNCQkKsrl27Wvv37zdXtBe42H7btWuX1apVK6t8+fJWUFCQVbt2bWvw4MFWcnKy2cINuv/++63Y2FgrMDDQioyMtNq2besKKpblvuPMYVmWVcgzPQAAAMWOMSsAAMCrEVYAAIBXI6wAAACvRlgBAABejbACAAC8GmEFAAB4NcIKAADwaoQVAADg1QgrAAqtT58+cjgccjgcCggIUFxcnJ588kmdPn3adGkASpBSpgsA4Ns6dOigSZMmKSMjQ6tXr1ZCQoIcDofGjh1rrKZdu3apevXqxj4fgHtxZgVAkQQFBalKlSqKiYlRly5d1K5dO82bN0+SVKNGDb3++uvZtr/iiis0fPhw13OHw6H3339fXbt2VUhIiOrUqaNZs2a5Xj927Jh69+6tyMhIBQcHq06dOpo0aVKeNcXFxaldu3aaPHmy0tLS3PZdAZhBWAHgNhs2bNDSpUsVGBhYoJ8bMWKE7r77bq1fv1633HKLevfuraNHj0qS/vvf/2rTpk364YcftHnzZo0fP14VK1bM8/02bdqkZs2a6bnnnlPlypV1//33a9GiReJWaIBvIqwAKJLZs2crNDRUpUuX1uWXX66DBw9q8ODBBXqPPn36qGfPnqpdu7ZGjRqlEydOaOXKlZLsLp0rr7xSTZs2VY0aNdSuXTt16tQpz/erW7euRo0apR07dmjWrFmyLEudOnVSrVq1NHz4cCUlJRX6+wLwPMIKgCK54YYbtG7dOq1YsUIJCQm67777dMcddxToPRo3buxqlylTRmFhYTp48KAkqV+/fvriiy90xRVX6Mknn9TSpUtd23bs2FGhoaEKDQ1Vw4YNL3hfh8OhG264QZMmTdKePXvUokULjRgxQo8++mghvy0AExhgC6BIypQpo9q1a0uSPvzwQ8XHx+uDDz5Q37595efnd0HXS0ZGxgXvERAQkO25w+FQVlaWJDuQ7Ny5U99//73mzZuntm3bKjExUS+//LLef/99nTp1Ksf3cFqzZo0++eQTff7553I4HHrsscf073//u8jfG4DnEFYAuI2fn5+eeeYZPfbYY+rVq5ciIyO1f/9+1+spKSmF6oKJjIxUQkKCEhIS1LJlSw0ePFgvv/yyqlatmuP2e/bs0aeffqrJkydr+/bt6tSpkz744AN16NBBpUrxvz3A1/BfLQC3uuuuuzR48GC9/fbbuvHGG/XRRx+pU6dOioiI0NChQ+Xv71+g9xs6dKiaNGmihg0bKj09XbNnz1b9+vXz/JnY2Fg1bdpUiYmJ6tmzp8qVK1eUrwTAMMIKALcqVaqUBgwYoHHjxmnbtm1KSkrSbbfdpvDwcI0cObLAZ1YCAwM1ZMgQ7dixQ8HBwWrZsqW++OKLPH9m48aNqlevXlG+BgAv4rCYywcAALwYs4EAAIBXI6wAAACvRlgBAABejbACAAC8GmEFAAB4NcIKAADwaoQVAADg1QgrAADAqxFWAACAVyOsAAAAr0ZYAQAAXo2wAgAAvNr/A4s1cr2WSeVWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# plot Loss\n",
        "plt.plot(total_loss, color='red')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Runs->')\n",
        "plt.title(\"Total Train Loss over time\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBXr3Bmqywoc"
      },
      "source": [
        "###Changing the Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu9Dxu5yNzpe",
        "outputId": "3448faa0-56c4-4a13-de40-f84499500c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on CUDA (GPU).\n"
          ]
        }
      ],
      "source": [
        "#Incresing the learning rate\n",
        "\n",
        "model = QAModel()\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "\n",
        "if next(model.parameters()).is_cuda:\n",
        "    print(\"Model is on CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"Model is on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5iV53Z3G4EN"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-4\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "optimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn1 = nn.CrossEntropyLoss()\n",
        "scheduler = ExponentialLR(optimizer1, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04JcrMIoN7gR",
        "outputId": "894191be-50ce-4b31-abbb-41b3f55fe8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch number is 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 249/2714 [05:44<57:42,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.442375\n",
            "current loss : 4.44983385848999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :   9%|▉         | 250/2714 [05:47<1:16:04,  1.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 499/2714 [11:38<52:02,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.490875\n",
            "current loss : 3.9724703669548034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  18%|█▊        | 500/2714 [11:41<1:10:22,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 749/2714 [17:31<45:54,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5111875\n",
            "current loss : 3.7699453376134238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  28%|██▊       | 750/2714 [17:35<1:04:40,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 999/2714 [23:26<40:16,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.52415625\n",
            "current loss : 3.6433178595304487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  37%|███▋      | 1000/2714 [23:29<53:44,  1.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  46%|████▌     | 1249/2714 [29:19<34:19,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5339125\n",
            "current loss : 3.54919780960083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  46%|████▌     | 1250/2714 [29:22<45:49,  1.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  55%|█████▌    | 1499/2714 [35:12<28:25,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5393541666666667\n",
            "current loss : 3.490472027460734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  55%|█████▌    | 1500/2714 [35:15<37:48,  1.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  64%|██████▍   | 1749/2714 [41:05<22:39,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5444642857142857\n",
            "current loss : 3.442061501775469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  64%|██████▍   | 1750/2714 [41:08<30:09,  1.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 1999/2714 [46:58<16:41,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5497890625\n",
            "current loss : 3.392787834882736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  74%|███████▎  | 2000/2714 [47:01<22:23,  1.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2249/2714 [52:52<10:55,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.5529444444444445\n",
            "current loss : 3.355032346036699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  83%|████████▎ | 2250/2714 [52:55<14:41,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2499/2714 [58:45<05:02,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.55543125\n",
            "current loss : 3.325522145175934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  92%|█████████▏| 2500/2714 [58:51<10:11,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:03:52<00:00,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.5581418109855937      Train Loss: 3.304104300790968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#training\n",
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer1, loss_fn1, 'checkpoint_loss_inc.pth')\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWm9MjaPOJje",
        "outputId": "98fc9b74-8e51-4924-c234-a698b499ed79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:30<00:00,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.5882056451612904 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#testing\n",
        "#testing the model\n",
        "\n",
        "acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "print(f\"Testing Accuracy: {test_acc} \" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tEy9uX0OOZl"
      },
      "source": [
        "####Decreasing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hHREWBtyuua",
        "outputId": "f3e0de12-c6bb-42d2-9a92-fa62df85e99a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on CUDA (GPU).\n"
          ]
        }
      ],
      "source": [
        "#Decreasing the Learning rate\n",
        "model = QAModel()\n",
        "\n",
        "model = model.to('cuda')\n",
        "\n",
        "\n",
        "if next(model.parameters()).is_cuda:\n",
        "    print(\"Model is on CUDA (GPU).\")\n",
        "else:\n",
        "    print(\"Model is on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUrcUAouN40I"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-6\n",
        "weight_decay = 2e-2\n",
        "gamma = 0.9\n",
        "optimizer1 = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fn1 = nn.CrossEntropyLoss()\n",
        "scheduler = ExponentialLR(optimizer1, gamma=gamma)\n",
        "total_accuracy = []\n",
        "total_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dw3rx-7OFpJ",
        "outputId": "77e59260-a4d7-4a89-c06b-33779f75c267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch number is 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :   9%|▉         | 249/2714 [05:43<57:33,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.0515\n",
            "current loss : 9.892909648895264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :   9%|▉         | 250/2714 [05:46<1:17:20,  1.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  18%|█▊        | 499/2714 [11:36<51:51,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.11334375\n",
            "current loss : 8.64912321472168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  18%|█▊        | 500/2714 [11:39<1:10:10,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  28%|██▊       | 749/2714 [17:29<46:18,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.1764375\n",
            "current loss : 7.647636007944743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  28%|██▊       | 750/2714 [17:32<1:02:30,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  37%|███▋      | 999/2714 [23:23<40:11,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.229453125\n",
            "current loss : 6.943855566501617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  37%|███▋      | 1000/2714 [23:26<53:46,  1.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  46%|████▌     | 1249/2714 [29:16<34:22,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.27165\n",
            "current loss : 6.434810050392151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  46%|████▌     | 1250/2714 [29:19<46:27,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  55%|█████▌    | 1499/2714 [35:09<28:31,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.305625\n",
            "current loss : 6.040744129975637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  55%|█████▌    | 1500/2714 [35:21<1:34:31,  4.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  64%|██████▍   | 1749/2714 [41:12<22:41,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.33435714285714285\n",
            "current loss : 5.7212984051023215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  64%|██████▍   | 1750/2714 [41:16<35:48,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  74%|███████▎  | 1999/2714 [47:06<16:51,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.3560625\n",
            "current loss : 5.476795455217362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  74%|███████▎  | 2000/2714 [47:09<22:39,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  83%|████████▎ | 2249/2714 [53:00<10:54,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.3748888888888889\n",
            "current loss : 5.271304281340705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  83%|████████▎ | 2250/2714 [53:03<15:11,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number :  92%|█████████▏| 2499/2714 [58:53<05:02,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current accuracy : 0.391125\n",
            "current loss : 5.097340122032166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCurrent epoch number :  92%|█████████▏| 2500/2714 [58:56<06:46,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving the model for epoch number 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current epoch number : 100%|██████████| 2714/2714 [1:03:56<00:00,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.4025262527650959      Train Loss: 4.968911172452883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch number is \" + str(epoch))\n",
        "    train_acc, train_loss = train(model, train_data_loader, epoch+1, optimizer1, loss_fn1, 'checkpoint_loss_dec.pth')\n",
        "    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-NJRNamOLVJ",
        "outputId": "8fd81bbf-51d4-468f-8409-4246308ff682"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running Evaluation: 100%|██████████| 186/186 [01:29<00:00,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.5547715053763441 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#testing\n",
        "#testing the model\n",
        "\n",
        "acc_list, test_acc = eval_model(model, test_data_loader)\n",
        "print(f\"Testing Accuracy: {test_acc} \" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlJXncm1BgZ4"
      },
      "source": [
        "###Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmyJkpoSk34p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-CsIDzxBfjO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YxIqSeXvb514",
        "xqc1zLj_h5gn",
        "j4-o1Oq7qUli",
        "8jjUY2eWbCN-",
        "0utuWyj_yDMl",
        "KBXr3Bmqywoc"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}